field_name: ecommerce_and_retail
subfield: Product Catalog Management
task: Supplier and Vendor Product Data Integration
tool_description: |-
  **STEP 1 — Rate task difficulty**
  This task involves integrating product data from multiple suppliers with varying data formats, quality issues, and complex mapping requirements. The scope includes data validation, transformation, deduplication, and maintaining data integrity across different vendor systems. This is a **hard** task due to high coordination dependencies, significant risk of data errors impacting business operations, and complex data infrastructure requirements.

  **STEP 2 — Set a tool budget**
  Given the hard difficulty rating, I'm targeting **17 tools** within the 15-20 range to handle the comprehensive workflows involved in supplier data integration.

  **STEP 3 — List all tool names with dependencies and affordances**

  1. **Supplier Data Fetcher** - Consumes: supplier credentials, endpoints → Produces: raw supplier data
  2. **Data Format Validator** - Consumes: raw data, schema rules → Produces: validation reports
  3. **Field Mapping Engine** - Consumes: source fields, mapping rules → Produces: mapped data structures
  4. **Product Data Transformer** - Consumes: raw product data, transformation rules → Produces: standardized data
  5. **Duplicate Detection Tool** - Consumes: product datasets → Produces: duplicate identification reports
  6. **Data Quality Analyzer** - Consumes: product data → Produces: quality metrics and issue reports
  7. **Price Validation Tool** - Consumes: pricing data, validation rules → Produces: price validation results
  8. **Inventory Sync Manager** - Consumes: inventory data from multiple sources → Produces: synchronized inventory status
  9. **Category Mapping Tool** - Consumes: vendor categories, master taxonomy → Produces: standardized categorizations
  10. **Image URL Validator** - Consumes: product image URLs → Produces: validated image metadata
  11. **Product Merge Engine** - Consumes: duplicate product records → Produces: merged product records
  12. **Data Conflict Resolver** - Consumes: conflicting data points, resolution rules → Produces: resolved data
  13. **Supplier Performance Monitor** - Consumes: integration metrics, error logs → Produces: performance reports
  14. **Batch Processing Orchestrator** - Consumes: processing jobs, schedules → Produces: execution status
  15. **Data Lineage Tracker** - Consumes: data transformation steps → Produces: lineage documentation
  16. **Integration Status Reporter** - Consumes: all process outputs → Produces: comprehensive status reports
  17. **Error Recovery Manager** - Consumes: failed processes, error logs → Produces: recovery recommendations

  **STEP 4 — Multi-tool plans**

  **Simple Plans:**
  1. **Basic Data Fetch & Validate** (Supplier Data Fetcher → Data Format Validator → Integration Status Reporter): Retrieve and validate basic supplier data feeds
  2. **Quick Price Check** (Supplier Data Fetcher → Price Validation Tool → Integration Status Reporter): Validate pricing data from a single supplier

  **Medium Plans:**
  1. **Standard Product Integration** (Supplier Data Fetcher → Data Format Validator → Product Data Transformer → Field Mapping Engine → Category Mapping Tool → Integration Status Reporter): Complete single-supplier product integration workflow
  2. **Quality Assessment Flow** (Supplier Data Fetcher → Data Quality Analyzer → Image URL Validator → Price Validation Tool → Supplier Performance Monitor): Comprehensive data quality evaluation

  **Complex Plans:**
  1. **Full Multi-Supplier Integration** (Supplier Data Fetcher → Data Format Validator → Product Data Transformer → Field Mapping Engine → Duplicate Detection Tool → Product Merge Engine → Data Conflict Resolver → Category Mapping Tool → Inventory Sync Manager → Data Lineage Tracker → Integration Status Reporter): Complete end-to-end multi-supplier integration
  2. **Enterprise Recovery & Monitoring** (Batch Processing Orchestrator → Error Recovery Manager → Supplier Performance Monitor → Data Quality Analyzer → Data Conflict Resolver → Data Lineage Tracker → Integration Status Reporter): Advanced error handling and monitoring workflow

  **STEP 5 — Produce tools**

  ```json
  {
    "tool_name": "Supplier Data Fetcher",
    "tool_description": "Retrieves product data from supplier APIs or file systems using various authentication methods and data formats.",
    "parameters": {
      "supplier_id": {
        "type": "string",
        "required": true,
        "description": "Unique identifier for the supplier"
      },
      "data_source_type": {
        "type": "string",
        "required": true,
        "description": "Type of data source: api, ftp, sftp, csv_upload, xml_feed"
      },
      "endpoint_url": {
        "type": "string",
        "required": false,
        "description": "API endpoint or file server URL",
        "default": "None"
      },
      "auth_method": {
        "type": "string",
        "required": false,
        "description": "Authentication method: api_key, oauth, basic_auth, none",
        "default": "none"
      },
      "credentials": {
        "type": "string",
        "required": false,
        "description": "Encoded authentication credentials",
        "default": "None"
      }
    },
    "error_messages": [
      "Invalid supplier_id: Supplier ID must be a non-empty string and exist in the system.",
      "Unsupported data_source_type: Use one of [api, ftp, sftp, csv_upload, xml_feed].",
      "Authentication failed: Check credentials and auth_method compatibility with the data source.",
      "Connection timeout: Verify endpoint_url is accessible and responsive.",
      "Data format error: Source data format is corrupted or incompatible."
    ],
    "usage": "Specify supplier_id and data_source_type. For API sources, provide endpoint_url, auth_method, and credentials. The tool handles various data formats and returns structured supplier data.",
    "output_details": {
      "fetch_status": {
        "type": "string",
        "description": "Status of the data fetch operation"
      },
      "record_count": {
        "type": "integer",
        "description": "Number of product records retrieved"
      },
      "data_format": {
        "type": "string",
        "description": "Detected format of the retrieved data"
      },
      "fetch_timestamp": {
        "type": "string",
        "description": "Timestamp when data was fetched"
      },
      "error_details": {
        "type": "string",
        "description": "Detailed error information if fetch failed"
      }
    }
  }
  ```

  ```json
  {
    "tool_name": "Data Format Validator",
    "tool_description": "Validates incoming supplier data against predefined schemas and data quality rules to ensure compatibility with the catalog system.",
    "parameters": {
      "data_source": {
        "type": "string",
        "required": true,
        "description": "Source identifier for the data to validate"
      },
      "expected_format": {
        "type": "string",
        "required": true,
        "description": "Expected data format: json, xml, csv, tsv"
      },
      "validation_level": {
        "type": "string",
        "required": false,
        "description": "Validation strictness: strict, moderate, lenient",
        "default": "moderate"
      }
    },
    "error_messages": [
      "Invalid data_source: Data source identifier must be provided and exist in the system.",
      "Unsupported expected_format: Use one of [json, xml, csv, tsv].",
      "Schema validation failed: Data structure does not match expected format requirements.",
      "Invalid validation_level: Use one of [strict, moderate, lenient].",
      "Data corruption detected: Input data contains unreadable or corrupted sections."
    ],
    "usage": "Provide data_source and expected_format. Optionally set validation_level for different strictness levels. Returns detailed validation results with specific error locations.",
    "output_details": {
      "validation_status": {
        "type": "string",
        "description": "Overall validation result: passed, failed, warning"
      },
      "error_count": {
        "type": "integer",
        "description": "Total number of validation errors found"
      },
      "warning_count": {
        "type": "integer",
        "description": "Total number of validation warnings found"
      },
      "validated_records": {
        "type": "integer",
        "description": "Number of records that passed validation"
      },
      "validation_report": {
        "type": "string",
        "description": "Detailed validation report with specific issues"
      }
    }
  }
  ```

  ```json
  {
    "tool_name": "Field Mapping Engine",
    "tool_description": "Maps supplier-specific field names and values to standardized catalog schema fields using configurable mapping rules and transformations.",
    "parameters": {
      "supplier_id": {
        "type": "string",
        "required": true,
        "description": "Identifier for the supplier whose data is being mapped"
      },
      "source_fields": {
        "type": "array",
        "required": true,
        "description": "List of source field names from supplier data",
        "items": {"type": "string"},
        "minItems": 1,
        "maxItems": 100
      },
      "target_schema": {
        "type": "string",
        "required": true,
        "description": "Target schema version: v1, v2, latest"
      },
      "custom_mapping_rules": {
        "type": "array",
        "required": false,
        "description": "Custom field mapping rules in format 'source_field:target_field'",
        "items": {"type": "string"},
        "default": "None"
      },
      "transformation_type": {
        "type": "string",
        "required": false,
        "description": "Data transformation approach: direct, computed, conditional",
        "default": "direct"
      },
      "handle_missing_fields": {
        "type": "boolean",
        "required": false,
        "description": "Whether to create default values for missing required fields",
        "default": true
      }
    },
    "error_messages": [
      "Invalid supplier_id: Supplier must exist in the system and have mapping configuration.",
      "Empty source_fields: At least one source field must be provided for mapping.",
      "Unsupported target_schema: Use one of [v1, v2, latest].",
      "Invalid custom_mapping_rules format: Rules must be in 'source_field:target_field' format.",
      "Unsupported transformation_type: Use one of [direct, computed, conditional].",
      "Required field mapping failed: Critical fields could not be mapped and handle_missing_fields is false."
    ],
    "usage": "Provide supplier_id, source_fields, and target_schema. Optionally specify custom_mapping_rules, transformation_type, and handle_missing_fields. Returns mapped field structure and transformation details.",
    "output_details": {
      "mapping_status": {
        "type": "string",
        "description": "Overall mapping result: success, partial, failed"
      },
      "mapped_fields_count": {
        "type": "integer",
        "description": "Number of successfully mapped fields"
      },
      "unmapped_fields": {
        "type": "array",
        "items": {"type": "string"},
        "description": "List of source fields that could not be mapped"
      },
      "transformation_log": {
        "type": "string",
        "description": "Log of transformations applied during mapping"
      },
      "mapping_confidence": {
        "type": "number",
        "description": "Confidence score for the mapping accuracy (0-1)"
      }
    }
  }
  ```

  ```json
  {
    "tool_name": "Product Data Transformer",
    "tool_description": "Transforms and standardizes product data from supplier formats to catalog-ready format including data cleansing, normalization, and enrichment.",
    "parameters": {
      "input_data_id": {
        "type": "string",
        "required": true,
        "description": "Identifier for the input data to transform"
      },
      "transformation_rules": {
        "type": "array",
        "required": true,
        "description": "List of transformation rules to apply",
        "items": {"type": "string"},
        "minItems": 1,
        "maxItems": 50
      },
      "data_cleansing_level": {
        "type": "string",
        "required": false,
        "description": "Intensity of data cleansing: basic, standard, aggressive",
        "default": "standard"
      },
      "preserve_original": {
        "type": "boolean",
        "required": false,
        "description": "Whether to preserve original data alongside transformed data",
        "default": true
      },
      "enrichment_enabled": {
        "type": "boolean",
        "required": false,
        "description": "Enable automatic data enrichment from external sources",
        "default": false
      }
    },
    "error_messages": [
      "Invalid input_data_id: Input data identifier must exist and be accessible.",
      "Empty transformation_rules: At least one transformation rule must be specified.",
      "Invalid transformation_rules format: Rules must follow the expected syntax pattern.",
      "Unsupported data_cleansing_level: Use one of [basic, standard, aggressive].",
      "Transformation failed: One or more transformation rules could not be applied successfully.",
      "Data integrity violation: Transformed data violates catalog system constraints."
    ],
    "usage": "Specify input_data_id and transformation_rules. Configure data_cleansing_level, preserve_original, and enrichment_enabled as needed. Returns transformed data with quality metrics.",
    "output_details": {
      "transformation_status": {
        "type": "string",
        "description": "Status of transformation process: completed, partial, failed"
      },
      "transformed_records": {
        "type": "integer",
        "description": "Number of records successfully transformed"
      },
      "failed_records": {
        "type": "integer",
        "description": "Number of records that failed transformation"
      },
      "quality_score": {
        "type": "number",
        "description": "Overall data quality score after transformation (0-1)"
      },
      "enrichment_additions": {
        "type": "integer",
        "description": "Number of data points added through enrichment"
      }
    }
  }
  ```

  ```json
  {
    "tool_name": "Duplicate Detection Tool",
    "tool_description": "Identifies potential duplicate products across supplier datasets using fuzzy matching algorithms and configurable similarity thresholds.",
    "parameters": {
      "dataset_ids": {
        "type": "array",
        "required": true,
        "description": "List of dataset identifiers to scan for duplicates",
        "items": {"type": "string"},
        "minItems": 1,
        "maxItems": 20
      },
      "matching_algorithm": {
        "type": "string",
        "required": false,
        "description": "Algorithm for duplicate detection: fuzzy, exact, semantic, hybrid",
        "default": "hybrid"
      },
      "similarity_threshold": {
        "type": "number",
        "required": false,
        "description": "Minimum similarity score to consider as duplicate (0.0-1.0)",
        "default": 0.85
      },
      "comparison_fields": {
        "type": "array",
        "required": false,
        "description": "Fields to use for comparison: name, sku, description, price, brand",
        "items": {"type": "string"},
        "default": "None"
      }
    },
    "error_messages": [
      "Invalid dataset_ids: All dataset identifiers must exist and be accessible.",
      "Unsupported matching_algorithm: Use one of [fuzzy, exact, semantic, hybrid].",
      "Invalid similarity_threshold: Threshold must be between 0.0 and 1.0.",
      "Invalid comparison_fields: Use valid field names from the product schema.",
      "Processing timeout: Duplicate detection took too long, try reducing dataset size or adjusting parameters."
    ],
    "usage": "Provide dataset_ids to scan. Configure matching_algorithm, similarity_threshold, and comparison_fields for fine-tuning. Returns detailed duplicate analysis with confidence scores.",
    "output_details": {
      "detection_status": {
        "type": "string",
        "description": "Status of duplicate detection process"
      },
      "duplicate_pairs_found": {
        "type": "integer",
        "description": "Number of potential duplicate pairs identified"
      },
      "confidence_distribution": {
        "type": "string",
        "description": "Distribution of confidence scores for detected duplicates"
      },
      "processing_time": {
        "type": "number",
        "description": "Time taken for duplicate detection in seconds"
      },
      "recommended_actions": {
        "type": "array",
        "items": {"type": "string"},
        "description": "Recommended actions for handling detected duplicates"
      }
    }
  }
  ```

  ```json
  {
    "tool_name": "Data Quality Analyzer",
    "tool_description": "Analyzes product data quality across multiple dimensions including completeness, accuracy, consistency, and freshness with detailed scoring and recommendations.",
    "parameters": {
      "data_source_id": {
        "type": "string",
        "required": true,
        "description": "Identifier for the data source to analyze"
      },
      "quality_dimensions": {
        "type": "array",
        "required": true,
        "description": "Quality dimensions to evaluate",
        "items": {"type": "string"},
        "minItems": 1,
        "maxItems": 10
      },
      "benchmark_dataset": {
        "type": "string",
        "required": false,
        "description": "Reference dataset for comparison analysis",
        "default": "None"
      },
      "quality_thresholds": {
        "type": "array",
        "required": false,
        "description": "Custom quality thresholds as percentage values",
        "items": {"type": "number"},
        "default": "None"
      },
      "analysis_depth": {
        "type": "string",
        "required": false,
        "description": "Depth of analysis: surface, standard, deep",
        "default": "standard"
      },
      "generate_recommendations": {
        "type": "boolean",
        "required": false,
        "description": "Whether to generate improvement recommendations",
        "default": true
      },
      "field_priority_weights": {
        "type": "array",
        "required": false,
        "description": "Priority weights for different fields (0.0-1.0)",
        "items": {"type": "number"},
        "default": "None"
      }
    },
    "error_messages": [
      "Invalid data_source_id: Data source must exist and be accessible for analysis.",
      "Invalid quality_dimensions: Use valid dimension names like completeness, accuracy, consistency.",
      "Invalid quality_thresholds: Thresholds must be numbers between 0 and 100.",
      "Unsupported analysis_depth: Use one of [surface, standard, deep].",
      "Invalid field_priority_weights: Weights must be numbers between 0.0 and 1.0.",
      "Benchmark dataset not found: Specified benchmark dataset does not exist or is inaccessible."
    ],
    "usage": "Specify data_source_id and quality_dimensions to analyze. Optionally provide benchmark_dataset, quality_thresholds, analysis_depth, and field_priority_weights. Returns comprehensive quality assessment with actionable insights.",
    "output_details": {
      "overall_quality_score": {
        "type": "number",
        "description": "Overall quality score from 0 to 100"
      },
      "dimension_scores": {
        "type": "array",
        "items": {"type": "number"},
        "description": "Individual scores for each quality dimension"
      },
      "critical_issues_count": {
        "type": "integer",
        "description": "Number of critical quality issues identified"
      },
      "improvement_potential": {
        "type": "number",
        "description": "Estimated improvement potential percentage"
      },
      "quality_trends": {
        "type": "string",
        "description": "Analysis of quality trends over time"
      },
      "recommendations": {
        "type": "array",
        "items": {"type": "string"},
        "description": "Specific recommendations for quality improvement"
      }
    }
  }
  ```

  ```json
  {
    "tool_name": "Price Validation Tool",
    "tool_description": "Validates product pricing data for accuracy, consistency, and market reasonableness using configurable business rules and market benchmarks.",
    "parameters": {
      "price_data_source": {
        "type": "string",
        "required": true,
        "description": "Source identifier for pricing data to validate"
      },
      "validation_rules": {
        "type": "array",
        "required": true,
        "description": "List of validation rules to apply",
        "items": {"type": "string"},
        "minItems": 1,
        "maxItems": 15
      },
      "currency": {
        "type": "string",
        "required": true,
        "description": "Currency code for price validation (ISO 4217)"
      },
      "market_comparison": {
        "type": "boolean",
        "required": false,
        "description": "Enable comparison with market benchmark prices",
        "default": false
      },
      "tolerance_percentage": {
        "type": "number",
        "required": false,
        "description": "Acceptable variance percentage for price validation",
        "default": 10.0
      }
    },
    "error_messages": [
      "Invalid price_data_source: Price data source must exist and contain valid pricing information.",
      "Empty validation_rules: At least one validation rule must be specified.",
      "Invalid currency code: Use a valid ISO 4217 currency code.",
      "Invalid tolerance_percentage: Tolerance must be a positive number between 0.1 and 100.",
      "Market benchmark unavailable: Market comparison requested but benchmark data is not available for the specified currency or region."
    ],
    "usage": "Provide price_data_source, validation_rules, and currency. Optionally enable market_comparison and set tolerance_percentage. Returns detailed price validation results with flagged anomalies.",
    "output_details": {
      "validation_status": {
        "type": "string",
        "description": "Overall price validation result"
      },
      "validated_price_count": {
        "type": "integer",
        "description": "Number of prices that passed validation"
      },
      "flagged_prices_count": {
        "type": "integer",
        "description": "Number of prices flagged for review"
      },
      "average_variance": {
        "type": "number",
        "description": "Average variance from expected price ranges"
      },
      "anomaly_details": {
        "type": "string",
        "description": "Detailed information about price anomalies detected"
      }
    }
  }
  ```

  ```json
  {
    "tool_name": "Inventory Sync Manager",
    "tool_description": "Synchronizes inventory levels and availability status across multiple supplier systems with real-time updates and conflict resolution.",
    "parameters": {
      "supplier_systems": {
        "type": "array",
        "required": true,
        "description": "List of supplier system identifiers to synchronize",
        "items": {"type": "string"},
        "minItems": 1,
        "maxItems": 25
      },
      "sync_frequency": {
        "type": "string",
        "required": true,
        "description": "Synchronization frequency: real_time, hourly, daily, weekly"
      },
      "conflict_resolution": {
        "type": "string",
        "required": false,
        "description": "Strategy for resolving inventory conflicts: latest, highest, lowest, average",
        "default": "latest"
      },
      "minimum_threshold": {
        "type": "integer",
        "required": false,
        "description": "Minimum inventory threshold for availability status",
        "default": 0
      },
      "enable_backorder": {
        "type": "boolean",
        "required": false,
        "description": "Whether to enable backorder status for out-of-stock items",
        "default": false
      },
      "priority_suppliers": {
        "type": "array",
        "required": false,
        "description": "List of priority supplier IDs for conflict resolution",
        "items": {"type": "string"},
        "default": "None"
      },
      "notification_threshold": {
        "type": "integer",
        "required": false,
        "description": "Inventory level that triggers low stock notifications",
        "default": 10
      }
    },
    "error_messages": [
      "Invalid supplier_systems: All supplier system identifiers must be valid and accessible.",
      "Unsupported sync_frequency: Use one of [real_time, hourly, daily, weekly].",
      "Invalid conflict_resolution strategy: Use one of [latest, highest, lowest, average].",
      "Invalid threshold values: minimum_threshold and notification_threshold must be non-negative integers.",
      "Sync operation failed: Unable to synchronize with one or more supplier systems.",
      "Priority suppliers not found: One or more priority suppliers in the list do not exist."
    ],
    "usage": "Specify supplier_systems and sync_frequency. Configure conflict_resolution, thresholds, and notification settings as needed. Returns synchronization status and inventory summary.",
    "output_details": {
      "sync_status": {
        "type": "string",
        "description": "Overall synchronization status"
      },
      "synchronized_products": {
        "type": "integer",
        "description": "Number of products successfully synchronized"
      },
      "sync_conflicts": {
        "type": "integer",
        "description": "Number of conflicts encountered during synchronization"
      },
      "low_stock_alerts": {
        "type": "integer",
        "description": "Number of products below notification threshold"
      },
      "last_sync_timestamp": {
        "type": "string",
        "description": "Timestamp of the last successful synchronization"
      },
      "system_health": {
        "type": "array",
        "items": {"type": "string"},
        "description": "Health status of each connected supplier system"
      }
    }
  }
  ```

  ```json
  {
    "tool_name": "Category Mapping Tool",
    "tool_description": "Maps supplier-specific product categories to standardized catalog taxonomy using machine learning and manual mapping rules.",
    "parameters": {
      "source_categories": {
        "type": "array",
        "required": true,
        "description": "List of source category names from supplier",
        "items": {"type": "string"},
        "minItems": 1,
        "maxItems": 200
      },
      "target_taxonomy": {
        "type": "string",
        "required": true,
        "description": "Target taxonomy version to map to"
      },
      "confidence_threshold": {
        "type": "number",
        "required": false,
        "description": "Minimum confidence score for automatic mapping (0.0-1.0)",
        "default": 0.75
      },
      "use_ml_suggestions": {
        "type": "boolean",
        "required": false,
        "description": "Enable machine learning-based category suggestions",
        "default": true
      }
    },
    "error_messages": [
      "Empty source_categories: At least one source category must be provided for mapping.",
      "Invalid target_taxonomy: Target taxonomy version must exist in the system.",
      "Invalid confidence_threshold: Confidence threshold must be between 0.0 and 1.0.",
      "Mapping service unavailable: Category mapping service is currently unavailable.",
      "Taxonomy mismatch: Source categories cannot be mapped to the specified target taxonomy."
    ],
    "usage": "Provide source_categories and target_taxonomy. Adjust confidence_threshold and use_ml_suggestions for optimal mapping results. Returns mapped categories with confidence scores.",
    "output_details": {
      "mapping_status": {
        "type": "string",
        "description": "Overall category mapping result"
      },
      "mapped_categories": {
        "type": "integer",
        "description": "Number of categories successfully mapped"
      },
      "unmapped_categories": {
        "type": "integer",
        "description": "Number of categories requiring manual review"
      },
      "average_confidence": {
        "type": "number",
        "description": "Average confidence score of all mappings"
      },
      "suggestions_used": {
        "type": "integer",
        "description": "Number of ML suggestions applied"
      }
    }
  }
  ```

  ```json
  {
    "tool_name": "Image URL Validator",
    "tool_description": "Validates product image URLs for accessibility, format compatibility, and quality standards with batch processing capabilities.",
    "parameters": {
      "image_urls": {
        "type": "array",
        "required": true,
        "description": "List of image URLs to validate",
        "items": {"type": "string"},
        "minItems": 1,
        "maxItems": 1000
      },
      "required_formats": {
        "type": "array",
        "required": false,
        "description": "Accepted image formats",
        "items": {"type": "string"},
        "default": "None"
      },
      "min_resolution": {
        "type": "string",
        "required": false,
        "description": "Minimum image resolution in WxH format",
        "default": "100x100"
      },
      "max_file_size": {
        "type": "integer",
        "required": false,
        "description": "Maximum file size in KB",
        "default": 5000
      }
    },
    "error_messages": [
      "Empty image_urls: At least one image URL must be provided for validation.",
      "Invalid URL format: One or more URLs have invalid format or syntax.",
      "Invalid required_formats: Use valid image format extensions like jpg, png, gif, webp.",
      "Invalid min_resolution format: Use WxH format like 800x600.",
      "Invalid max_file_size: File size limit must be a positive integer in KB."
    ],
    "usage": "Provide image_urls array. Optionally specify required_formats, min_resolution, and max_file_size constraints. Returns validation results for each URL with detailed feedback.",
    "output_details": {
      "validation_summary": {
        "type": "string",
        "description": "Summary of image validation results"
      },
      "valid_images": {
        "type": "integer",
        "description": "Number of images that passed validation"
      },
      "invalid_images": {
        "type": "integer",
        "description": "Number of images that failed validation"
      },
      "average_file_size": {
        "type": "number",
        "description": "Average file size of valid images in KB"
      },
      "format_distribution": {
        "type": "string",
        "description": "Distribution of image formats found"
      }
    }
  }
  ```

  ```json
  {
    "tool_name": "Product Merge Engine",
    "tool_description": "Merges duplicate product records from multiple suppliers into consolidated master records while preserving important data and maintaining audit trails.",
    "parameters": {
      "duplicate_pairs": {
        "type": "array",
        "required": true,
        "description": "Array of product ID pairs identified as duplicates",
        "items": {"type": "string"},
        "minItems": 1,
        "maxItems": 500
      },
      "merge_strategy": {
        "type": "string",
        "required": true,
        "description": "Strategy for merging: best_quality, most_complete, supplier_priority, manual_rules"
      },
      "preserve_variants": {
        "type": "boolean",
        "required": false,
        "description": "Whether to preserve product variants as separate entities",
        "default": true
      },
      "audit_trail": {
        "type": "boolean",
        "

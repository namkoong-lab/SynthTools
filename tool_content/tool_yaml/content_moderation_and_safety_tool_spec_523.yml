field_name: content_moderation_and_safety
subfield: Image and Video Content Analysis
task: Identify and flag violence, gore, or disturbing imagery across media files
tool_description: "**STEP 1 — Rate task difficulty**\n\nThis task is **hard** due to the high complexity of visual content analysis, ambiguous boundaries between acceptable and unacceptable content, critical safety implications requiring high accuracy to prevent harmful content exposure, and substantial infrastructure needs for processing diverse media formats at scale.\n\n**STEP 2 — Set a tool budget**\n\nGiven the hard difficulty rating, I'll target **17 tools** to cover the comprehensive workflow from media ingestion through final moderation decisions.\n\n**STEP 3 — List all tool names and dependencies**\n\nTools and their data flow:\n- **Media File Validator** → validates files → **Media Metadata Extractor**\n- **Media Metadata Extractor** → extracts metadata → **Frame Extractor**, **Audio Extractor**\n- **Frame Extractor** → extracts frames → **Violence Detection Engine**, **Gore Detection Engine** \n- **Violence Detection Engine** → violence scores → **Content Severity Analyzer**\n- **Gore Detection Engine** → gore scores → **Content Severity Analyzer**\n- **Audio Extractor** → audio data → **Audio Violence Detector**\n- **Audio Violence Detector** → audio scores → **Content Severity Analyzer**\n- **Content Severity Analyzer** → severity assessment → **Moderation Decision Engine**\n- **Human Review Queue Manager** ← queues uncertain cases ← **Moderation Decision Engine**\n- **Content Flagging System** ← flags violations ← **Moderation Decision Engine**\n- **False Positive Analyzer** → analyzes misclassifications → **Model Performance Tracker**\n- **Batch Processing Controller** → orchestrates bulk processing → multiple detection tools\n- **Content Hash Generator** → creates fingerprints → **Duplicate Content Detector**\n- **Duplicate Content Detector** → identifies duplicates → **Moderation Decision Engine**\n- **Moderation Report Generator** ← generates reports ← **Content Flagging System**\n- **Model Performance Tracker** → tracks metrics → **Moderation Report Generator**\n\n**STEP 4 — Multi-tool plans**\n\n**Simple Plans:**\n1. Single image check: Media File Validator → Frame Extractor → Violence Detection Engine → Moderation Decision Engine\n2. Duplicate detection: Content Hash Generator → Duplicate Content Detector → Content Flagging System\n\n**Medium Plans:**\n1. Video analysis: Media File Validator → Media Metadata Extractor → Frame Extractor → Violence Detection Engine + Gore Detection Engine → Content Severity Analyzer → Moderation Decision Engine\n2. Audio-visual assessment: Frame Extractor + Audio Extractor → Violence Detection Engine + Audio Violence Detector → Content Severity Analyzer → Moderation Decision Engine\n\n**Complex Plans:**\n1. Full content pipeline: Media File Validator → Media Metadata Extractor → Frame Extractor + Audio Extractor → Violence Detection Engine + Gore Detection Engine + Audio Violence Detector → Content Severity Analyzer → Moderation Decision Engine → Content Flagging System + Human Review Queue Manager → Moderation Report Generator\n2. Batch processing with quality control: Batch Processing Controller → all detection tools → Content Severity Analyzer → Moderation Decision Engine → False Positive Analyzer → Model Performance Tracker → Moderation Report Generator\n\n**STEP 5 — Produce tools**\n\n```json\n{\n  \"tool_name\": \"Media File Validator\",\n  \"tool_description\": \"Validates media files for format compatibility, corruption, and basic properties before content analysis.\",\n  \"parameters\": {\n    \"file_path\": {\n      \"type\": \"string\",\n      \"required\": true,\n      \"description\": \"Path to the media file to validate\"\n    },\n    \"max_file_size_mb\": {\n      \"type\": \"number\",\n      \"required\": false,\n      \"description\": \"Maximum allowed file size in megabytes\",\n      \"default\": 500\n    }\n  },\n  \"error_messages\": [\n    \"File not found: The specified file path does not exist or is inaccessible.\",\n    \"File size exceeded: File exceeds the maximum allowed size limit.\",\n    \"Unsupported format: File format is not supported for\
  \ content analysis.\",\n    \"Corrupted file: File appears to be corrupted or incomplete.\"\n  ],\n  \"usage\": \"Provide the file_path to validate media files before processing. Optionally set max_file_size_mb to control file size limits.\",\n  \"output_details\": {\n    \"is_valid\": {\n      \"type\": \"boolean\",\n      \"description\": \"Whether the file passed validation\"\n    },\n    \"file_format\": {\n      \"type\": \"string\",\n      \"description\": \"Detected file format (e.g., mp4, jpg, png)\"\n    },\n    \"file_size_mb\": {\n      \"type\": \"number\",\n      \"description\": \"File size in megabytes\"\n    },\n    \"validation_errors\": {\n      \"type\": \"array\",\n      \"items\": {\n        \"type\": \"string\"\n      },\n      \"description\": \"List of validation errors if any\"\n    }\n  }\n}\n```\n\n```json\n{\n  \"tool_name\": \"Media Metadata Extractor\",\n  \"tool_description\": \"Extracts comprehensive metadata from media files including duration, resolution, codec information, and technical properties.\",\n  \"parameters\": {\n    \"file_path\": {\n      \"type\": \"string\",\n      \"required\": true,\n      \"description\": \"Path to the validated media file\"\n    },\n    \"extract_thumbnails\": {\n      \"type\": \"boolean\",\n      \"required\": false,\n      \"description\": \"Whether to extract thumbnail images\",\n      \"default\": true\n    },\n    \"thumbnail_count\": {\n      \"type\": \"integer\",\n      \"required\": false,\n      \"description\": \"Number of thumbnails to extract (1-10)\",\n      \"default\": 3\n    }\n  },\n  \"error_messages\": [\n    \"Metadata extraction failed: Unable to read metadata from the file.\",\n    \"Invalid thumbnail count: thumbnail_count must be between 1 and 10.\",\n    \"Thumbnail extraction failed: Could not generate thumbnails from the media file.\"\n  ],\n  \"usage\": \"Provide file_path of a validated media file. Optionally configure thumbnail extraction settings.\",\n  \"output_details\": {\n    \"duration_seconds\": {\n      \"type\": \"number\",\n      \"description\": \"Duration of the media in seconds (0 for images)\"\n    },\n    \"width\": {\n      \"type\": \"integer\",\n      \"description\": \"Width in pixels\"\n    },\n    \"height\": {\n      \"type\": \"integer\",\n      \"description\": \"Height in pixels\"\n    },\n    \"frame_rate\": {\n      \"type\": \"number\",\n      \"description\": \"Frames per second for videos (0 for images)\"\n    },\n    \"codec\": {\n      \"type\": \"string\",\n      \"description\": \"Media codec information\"\n    },\n    \"has_audio\": {\n      \"type\": \"boolean\",\n      \"description\": \"Whether the file contains audio\"\n    },\n    \"thumbnail_paths\": {\n      \"type\": \"array\",\n      \"items\": {\n        \"type\": \"string\"\n      },\n      \"description\": \"Paths to generated thumbnail files\"\n    }\n  }\n}\n```\n\n```json\n{\n  \"tool_name\": \"Frame Extractor\",\n  \"tool_description\": \"Extracts frames from video files at specified intervals or timestamps for content analysis.\",\n  \"parameters\": {\n    \"video_path\": {\n      \"type\": \"string\",\n      \"required\": true,\n      \"description\": \"Path to the video file\"\n    },\n    \"extraction_method\": {\n      \"type\": \"string\",\n      \"required\": true,\n      \"description\": \"Method for frame extraction: interval, timestamps, uniform, or keyframes\"\n    },\n    \"interval_seconds\": {\n      \"type\": \"number\",\n      \"required\": false,\n      \"description\": \"Interval between extracted frames in seconds (for interval method)\",\n      \"default\": 1.0\n    },\n    \"timestamps\": {\n      \"type\": \"array\",\n      \"required\": false,\n      \"description\": \"Specific timestamps to extract frames (for timestamps method)\",\n      \"items\": {\n        \"type\": \"number\"\n      },\n      \"default\": []\n    },\n    \"max_frames\": {\n      \"type\": \"integer\",\n      \"required\": false,\n      \"description\": \"Maximum number of frames to extract (1-1000)\",\n      \"default\": 100\n\
  \    },\n    \"output_format\": {\n      \"type\": \"string\",\n      \"required\": false,\n      \"description\": \"Output format for frames: jpg or png\",\n      \"default\": \"jpg\"\n    }\n  },\n  \"error_messages\": [\n    \"Invalid extraction method: Use one of [interval, timestamps, uniform, keyframes].\",\n    \"Invalid interval: interval_seconds must be greater than 0.\",\n    \"Invalid timestamps: All timestamps must be non-negative and within video duration.\",\n    \"Max frames exceeded: max_frames must be between 1 and 1000.\",\n    \"Frame extraction failed: Could not extract frames from the video file.\"\n  ],\n  \"usage\": \"Provide video_path and extraction_method. Configure extraction parameters based on the chosen method.\",\n  \"output_details\": {\n    \"extracted_frames\": {\n      \"type\": \"array\",\n      \"items\": {\n        \"type\": \"string\"\n      },\n      \"description\": \"Paths to extracted frame image files\"\n    },\n    \"frame_timestamps\": {\n      \"type\": \"array\",\n      \"items\": {\n        \"type\": \"number\"\n      },\n      \"description\": \"Timestamps of extracted frames in seconds\"\n    },\n    \"total_frames_extracted\": {\n      \"type\": \"integer\",\n      \"description\": \"Total number of frames successfully extracted\"\n    }\n  }\n}\n```\n\n```json\n{\n  \"tool_name\": \"Violence Detection Engine\",\n  \"tool_description\": \"Analyzes images or video frames to detect violent content including fights, weapons, aggressive behavior, and threatening gestures using computer vision models.\",\n  \"parameters\": {\n    \"image_paths\": {\n      \"type\": \"array\",\n      \"required\": true,\n      \"description\": \"Paths to image files to analyze\",\n      \"items\": {\n        \"type\": \"string\"\n      },\n      \"minItems\": 1,\n      \"maxItems\": 100\n    },\n    \"detection_sensitivity\": {\n      \"type\": \"string\",\n      \"required\": false,\n      \"description\": \"Sensitivity level: low, medium, or high\",\n      \"default\": \"medium\"\n    },\n    \"violence_categories\": {\n      \"type\": \"array\",\n      \"required\": false,\n      \"description\": \"Specific violence categories to detect\",\n      \"items\": {\n        \"type\": \"string\"\n      },\n      \"default\": [\"weapons\", \"fighting\", \"aggressive_behavior\", \"threatening_gestures\"]\n    },\n    \"confidence_threshold\": {\n      \"type\": \"number\",\n      \"required\": false,\n      \"description\": \"Minimum confidence score for positive detection (0.0-1.0)\",\n      \"default\": 0.7\n    },\n    \"batch_processing\": {\n      \"type\": \"boolean\",\n      \"required\": false,\n      \"description\": \"Enable batch processing for multiple images\",\n      \"default\": true\n    }\n  },\n  \"error_messages\": [\n    \"Invalid image paths: One or more image files could not be found or read.\",\n    \"Invalid sensitivity level: Use one of [low, medium, high].\",\n    \"Invalid confidence threshold: Value must be between 0.0 and 1.0.\",\n    \"Too many images: Maximum 100 images per batch.\",\n    \"Detection model error: Violence detection model failed to process the images.\"\n  ],\n  \"usage\": \"Provide image_paths array with images to analyze. Configure detection parameters like sensitivity and categories as needed.\",\n  \"output_details\": {\n    \"overall_violence_score\": {\n      \"type\": \"number\",\n      \"description\": \"Overall violence score across all images (0.0-1.0)\"\n    },\n    \"image_scores\": {\n      \"type\": \"array\",\n      \"items\": {\n        \"type\": \"number\"\n      },\n      \"description\": \"Violence score for each input image\"\n    },\n    \"detected_categories\": {\n      \"type\": \"array\",\n      \"items\": {\n        \"type\": \"string\"\n      },\n      \"description\": \"Violence categories detected across all images\"\n    },\n    \"high_risk_images\": {\n      \"type\": \"array\",\n      \"items\": {\n        \"type\": \"string\"\n      },\n      \"description\": \"Paths to images with highest violence scores\"\n    },\n   \
  \ \"detection_details\": {\n      \"type\": \"array\",\n      \"items\": {\n        \"type\": \"string\"\n      },\n      \"description\": \"Detailed descriptions of detected violent content\"\n    }\n  }\n}\n```\n\n```json\n{\n  \"tool_name\": \"Gore Detection Engine\",\n  \"tool_description\": \"Identifies gore, blood, graphic injuries, and disturbing imagery in visual content using specialized computer vision models.\",\n  \"parameters\": {\n    \"image_paths\": {\n      \"type\": \"array\",\n      \"required\": true,\n      \"description\": \"Paths to image files to analyze for gore content\",\n      \"items\": {\n        \"type\": \"string\"\n      },\n      \"minItems\": 1,\n      \"maxItems\": 100\n    },\n    \"gore_categories\": {\n      \"type\": \"array\",\n      \"required\": false,\n      \"description\": \"Specific gore categories to detect\",\n      \"items\": {\n        \"type\": \"string\"\n      },\n      \"default\": [\"blood\", \"injuries\", \"corpses\", \"dismemberment\", \"medical_gore\"]\n    },\n    \"sensitivity_level\": {\n      \"type\": \"string\",\n      \"required\": false,\n      \"description\": \"Detection sensitivity: conservative, balanced, or aggressive\",\n      \"default\": \"balanced\"\n    },\n    \"medical_context_filter\": {\n      \"type\": \"boolean\",\n      \"required\": false,\n      \"description\": \"Apply filtering for legitimate medical/educational content\",\n      \"default\": true\n    }\n  },\n  \"error_messages\": [\n    \"Image processing failed: One or more images could not be processed for gore detection.\",\n    \"Invalid sensitivity level: Use one of [conservative, balanced, aggressive].\",\n    \"Invalid gore categories: Specify valid categories from the supported list.\",\n    \"Batch size exceeded: Maximum 100 images per request.\",\n    \"Gore detection model unavailable: The detection model is currently unavailable.\"\n  ],\n  \"usage\": \"Provide image_paths array for gore analysis. Optionally configure gore_categories, sensitivity_level, and medical_context_filter.\",\n  \"output_details\": {\n    \"overall_gore_score\": {\n      \"type\": \"number\",\n      \"description\": \"Overall gore severity score (0.0-1.0)\"\n    },\n    \"image_gore_scores\": {\n      \"type\": \"array\",\n      \"items\": {\n        \"type\": \"number\"\n      },\n      \"description\": \"Gore score for each analyzed image\"\n    },\n    \"detected_gore_types\": {\n      \"type\": \"array\",\n      \"items\": {\n        \"type\": \"string\"\n      },\n      \"description\": \"Types of gore content detected\"\n    },\n    \"flagged_images\": {\n      \"type\": \"array\",\n      \"items\": {\n        \"type\": \"string\"\n      },\n      \"description\": \"Paths to images flagged for gore content\"\n    },\n    \"medical_context_detected\": {\n      \"type\": \"boolean\",\n      \"description\": \"Whether medical/educational context was detected\"\n    }\n  }\n}\n```\n\n```json\n{\n  \"tool_name\": \"Audio Extractor\",\n  \"tool_description\": \"Extracts and preprocesses audio tracks from video files for content analysis, with options for segmentation and format conversion.\",\n  \"parameters\": {\n    \"video_path\": {\n      \"type\": \"string\",\n      \"required\": true,\n      \"description\": \"Path to the video file containing audio\"\n    },\n    \"output_format\": {\n      \"type\": \"string\",\n      \"required\": false,\n      \"description\": \"Audio output format: wav, mp3, or flac\",\n      \"default\": \"wav\"\n    },\n    \"sample_rate\": {\n      \"type\": \"integer\",\n      \"required\": false,\n      \"description\": \"Audio sample rate in Hz\",\n      \"default\": 44100\n    },\n    \"segment_duration\": {\n      \"type\": \"number\",\n      \"required\": false,\n      \"description\": \"Duration of audio segments in seconds (0 for no segmentation)\",\n      \"default\": 30.0\n    }\n  },\n  \"error_messages\": [\n    \"No audio track found: The video file does not contain an audio track.\",\n    \"Audio extraction failed: Could not extract audio from the video\
  \ file.\",\n    \"Invalid output format: Use one of [wav, mp3, flac].\",\n    \"Invalid sample rate: Sample rate must be a positive integer.\",\n    \"Invalid segment duration: segment_duration must be greater than 0 or equal to 0 for no segmentation.\"\n  ],\n  \"usage\": \"Provide video_path to extract audio. Configure output_format, sample_rate, and segment_duration as needed for downstream analysis.\",\n  \"output_details\": {\n    \"audio_file_paths\": {\n      \"type\": \"array\",\n      \"items\": {\n        \"type\": \"string\"\n      },\n      \"description\": \"Paths to extracted audio files or segments\"\n    },\n    \"total_duration\": {\n      \"type\": \"number\",\n      \"description\": \"Total duration of extracted audio in seconds\"\n    },\n    \"segment_count\": {\n      \"type\": \"integer\",\n      \"description\": \"Number of audio segments created\"\n    },\n    \"audio_properties\": {\n      \"type\": \"string\",\n      \"description\": \"Technical properties of the extracted audio\"\n    }\n  }\n}\n```\n\n```json\n{\n  \"tool_name\": \"Audio Violence Detector\",\n  \"tool_description\": \"Analyzes audio content for violent sounds including screaming, gunshots, explosions, aggressive speech, and other audio indicators of violence.\",\n  \"parameters\": {\n    \"audio_file_paths\": {\n      \"type\": \"array\",\n      \"required\": true,\n      \"description\": \"Paths to audio files to analyze\",\n      \"items\": {\n        \"type\": \"string\"\n      },\n      \"minItems\": 1,\n      \"maxItems\": 50\n    },\n    \"violence_audio_types\": {\n      \"type\": \"array\",\n      \"required\": false,\n      \"description\": \"Types of violent audio to detect\",\n      \"items\": {\n        \"type\": \"string\"\n      },\n      \"default\": [\"screaming\", \"gunshots\", \"explosions\", \"aggressive_speech\", \"breaking_sounds\"]\n    },\n    \"language_filter\": {\n      \"type\": \"array\",\n      \"required\": false,\n      \"description\": \"Languages to analyze for speech content\",\n      \"items\": {\n        \"type\": \"string\"\n      },\n      \"default\": [\"en\", \"es\", \"fr\", \"de\"]\n    },\n    \"audio_sensitivity\": {\n      \"type\": \"string\",\n      \"required\": false,\n      \"description\": \"Detection sensitivity: low, medium, or high\",\n      \"default\": \"medium\"\n    },\n    \"background_noise_filter\": {\n      \"type\": \"boolean\",\n      \"required\": false,\n      \"description\": \"Apply background noise filtering\",\n      \"default\": true\n    }\n  },\n  \"error_messages\": [\n    \"Audio file not found: One or more audio files could not be accessed.\",\n    \"Invalid audio format: Audio files must be in supported formats (wav, mp3, flac).\",\n    \"Audio processing failed: Could not process audio for violence detection.\",\n    \"Invalid sensitivity level: Use one of [low, medium, high].\",\n    \"Too many audio files: Maximum 50 audio files per batch.\"\n  ],\n  \"usage\": \"Provide audio_file_paths for analysis. Configure violence_audio_types, language_filter, and sensitivity settings as needed.\",\n  \"output_details\": {\n    \"overall_audio_violence_score\": {\n      \"type\": \"number\",\n      \"description\": \"Overall violence score for all audio files (0.0-1.0)\"\n    },\n    \"file_violence_scores\": {\n      \"type\": \"array\",\n      \"items\": {\n        \"type\": \"number\"\n      },\n      \"description\": \"Violence score for each audio file\"\n    },\n    \"detected_violence_types\": {\n      \"type\": \"array\",\n      \"items\": {\n        \"type\": \"string\"\n      },\n      \"description\": \"Types of violent audio content detected\"\n    },\n    \"high_risk_segments\": {\n      \"type\": \"array\",\n      \"items\": {\n        \"type\": \"string\"\n      },\n      \"description\": \"Timestamps or identifiers of high-risk audio segments\"\n    },\n    \"transcribed_threats\": {\n      \"type\": \"array\",\n      \"items\": {\n        \"type\": \"string\"\n      },\n      \"description\": \"Transcribed threatening or violent speech content\"\
  \n    }\n  }\n}\n```\n\n```json\n{\n  \"tool_name\": \"Content Severity Analyzer\",\n  \"tool_description\": \"Combines multiple detection results to assess overall content severity and risk level, providing comprehensive content safety scoring.\",\n  \"parameters\": {\n    \"violence_score\": {\n      \"type\": \"number\",\n      \"required\": true,\n      \"description\": \"Violence detection score (0.0-1.0)\"\n    },\n    \"gore_score\": {\n      \"type\": \"number\",\n      \"required\": true,\n      \"description\": \"Gore detection score (0.0-1.0)\"\n    },\n    \"audio_violence_score\": {\n      \"type\": \"number\",\n      \"required\": false,\n      \"description\": \"Audio violence score (0.0-1.0)\",\n      \"default\": 0.0\n    },\n    \"content_duration\": {\n      \"type\": \"number\",\n      \"required\": true,\n      \"description\": \"Duration of content in seconds (use 0 for static images)\"\n    },\n    \"detected_categories\": {\n      \"type\": \"array\",\n      \"required\": true,\n      \"description\": \"All detected problematic content categories\",\n      \"items\": {\n        \"type\": \"string\"\n      }\n    },\n    \"context_factors\": {\n      \"type\": \"array\",\n      \"required\": false,\n      \"description\": \"Additional context factors affecting severity\",\n      \"items\": {\n        \"type\": \"string\"\n      },\n      \"default\": []\n    },\n    \"age_rating_context\": {\n      \"type\": \"string\",\n      \"required\": false,\n      \"description\": \"Target age rating context: G, PG, PG13, R, or unrated\",\n      \"default\": \"unrated\"\n    }\n  },\n  \"error_messages\": [\n    \"Invalid score values: All score parameters must be between 0.0 and 1.0.\",\n    \"Invalid duration: content_duration must be non-negative.\",\n    \"Empty categories: At least one detected category must be provided if any scores are above 0.0.\",\n    \"Invalid age rating: Use one of [G, PG, PG13, R, unrated].\",\n    \"Severity calculation failed: Could not compute content severity assessment.\"\n  ],\n  \"usage\": \"Provide violence_score, gore_score, content_duration, and detected_categories. Optionally include audio_violence_score, context_factors, and age_rating_context for more accurate assessment.\",\n  \"output_details\": {\n    \"overall_severity_score\": {\n      \"type\": \"number\",\n      \"description\": \"Combined severity score (0.0-1.0)\"\n    },\n    \"risk_level\": {\n      \"type\": \"string\",\n      \"description\": \"Risk classification: low, moderate, high, or extreme\"\n    },\n    \"primary_concerns\": {\n      \"type\": \"array\",\n      \"items\": {\n        \"type\": \"string\"\n      },\n      \"description\": \"Primary content safety concerns identified\"\n    },\n    \"recommended_action\": {\n      \"type\": \"string\",\n      \"description\": \"Recommended moderation action\"\n    },\n    \"severity_breakdown\": {\n      \"type\": \"string\",\n      \"description\": \"Detailed breakdown of severity factors\"\n    },\n    \"confidence_level\": {\n      \"type\": \"number\",\n      \"description\": \"Confidence in the severity assessment (0.0-1.0)\"\n    }\n  }\n}\n```\n\n```json\n{\n  \"tool_name\": \"Moderation Decision Engine\",\n  \"tool_description\": \"Makes final moderation decisions based on content severity analysis, applying platform policies and determining appropriate actions.\",\n  \"parameters\": {\n    \"severity_score\": {\n      \"type\": \"number\",\n      \"required\": true,\n      \"description\": \"Content severity score from analysis (0.0-1.0)\"\n    },\n    \"risk_level\": {\n      \"type\": \"string\",\n      \"required\": true,\n      \"description\": \"Risk level: low, moderate, high, or extreme\"\n    },\n    \"content_type\": {\n      \"type\": \"string\",\n      \"required\": true,\n      \"description\": \"Type of content: image, video, or audio\"\n    },\n    \"platform_policy\": {\n      \"type\": \"string\",\n      \"required\": true,\n      \"description\": \"Platform policy setting: strict, standard, or lenient\"\n    },\n    \"user_context\"\
  : {\n      \"type\": \"string\",\n      \"required\": false,\n      \"description\": \"User context: public, restricted, or private\",\n      \"default\": \"public\"\n    },\n    \"appeals_enabled\": {\n      \"type\": \"boolean\",\n      \"required\": false,\n      \"description\": \"Whether appeal process is available\",\n      \"default\": true\n    },\n    \"primary_concerns\": {\n      \"type\": \"array\",\n      \"required\": true,\n      \"description\": \"Primary safety concerns from severity analysis\",\n      \"items\": {\n        \"type\": \"string\"\n      }\n    },\n    \"confidence_level\": {\n      \"type\": \"number\",\n      \"required\": true,\n      \"description\": \"Confidence in the assessment (0.0-1.0)\"\n    },\n    \"human_review_threshold\": {\n      \"type\": \"number\",\n      \"required\": false,\n      \"description\": \"Confidence threshold below which human review is required\",\n      \"default\": 0.8\n    }\n  },\n  \"error_messages\": [\n    \"Invalid severity score: severity_score must be between 0.0 and 1.0.\",\n    \"Invalid risk level: Use one of [low, moderate, high, extreme].\",\n    \"Invalid content type: Use one of [image, video, audio].\",\n    \"Invalid platform policy: Use one of [strict, standard, lenient].\",\n    \"Invalid user context: Use one of [public, restricted, private].\",\n    \"Invalid confidence level: confidence_level must be between 0.0 and 1.0.\",\n    \"Decision processing failed: Could not generate moderation decision.\"\n  ],\n  \"usage\": \"Provide severity analysis results including severity_score, risk_level, content_type, platform_policy, primary_concerns, and confidence_level. Configure review thresholds and context as needed.\",\n  \"output_details\": {\n    \"moderation_action\": {\n      \"type\": \"string\",\n      \"description\": \"Final moderation action: approve, flag, remove, or review\"\n    },\n    \"action_reason\": {\n      \"type\": \"string\",\n      \"description\": \"Explanation for the moderation decision\"\n    },\n    \"requires_human_review\": {\n      \"type\": \"boolean\",\n      \"description\": \"Whether human review is required\"\n    },\n    \"content_warnings\": {\n      \"type\": \"array\",\n      \"items\": {\n        \"type\": \"string\"\n      },\n      \"description\": \"Content warnings to display if approved with restrictions\"\n    },\n    \"appeal_eligible\": {\n      \"type\": \"boolean\",\n      \"description\": \"Whether the decision is eligible for appeal\"\n    },\n    \"escalation_priority\": {\n      \"type\": \"string\",\n      \"description\": \"Priority level for escalation: low, normal, high, urgent\"\n    }\n  }\n}\n```\n\n```json\n{\n  \"tool_name\": \"Human Review Queue Manager\",\n  \"tool_description\": \"Manages the queue of content requiring human review, prioritizing items based on urgency and routing to appropriate reviewers.\",\n  \"parameters\": {\n    \"content_id\": {\n      \"type\": \"string\",\n      \"required\": true,\n      \"description\": \"Unique identifier for the content item\"\n    },\n    \"moderation_decision\": {\n      \"type\": \"string\",\n      \"required\": true,\n      \"description\": \"Initial moderation decision requiring review\"\n    },\n    \"priority_level\": {\n      \"type\": \"string\",\n      \"required\": true,\n      \"description\": \"Review priority: low, normal, high, or urgent\"\n    },\n    \"content_summary\": {\n      \"type\": \"string\",\n      \"required\": true,\n      \"description\": \"Summary of content and detected issues\"\n    },\n    \"reviewer_specialization\": {\n      \"type\": \"string\",\n      \"required\": false,\n      \"description\": \"Required reviewer expertise: general, violence, gore, or sensitive\",\n      \"default\": \"general\"\n    }\n  },\n  \"error_messages\": [\n    \"Invalid content ID: content_id must be a non-empty string.\",\n    \"Invalid priority level: Use one of [low, normal, high, urgent].\",\n    \"Invalid reviewer specialization: Use one of [general, violence, gore, sensitive].\",\n    \"Queue management failed:\
  \ Could not add item to review queue.\",\n    \"Content summary required: content_summary cannot be empty.\"\n  ],\n  \"usage\": \"Provide content_id, moderation_decision, priority_level, and content_summary to queue content for human review. Optionally specify reviewer_specialization for expert review.\",\n  \"output_details\": {\n    \"queue_position\": {\n      \"type\": \"integer\",\n      \"description\": \"Position in the review queue\"\n    },\n    \"estimated_review_time\": {\n      \"type\": \"string\",\n      \"description\": \"Estimated time until review completion\"\n    },\n    \"assigned_reviewer\": {\n      \"type\": \"string\",\n      \"description\": \"ID or name of assigned reviewer (if available)\"\n    },\n    \"review_ticket_id\": {\n      \"type\": \"string\",\n      \"description\": \"Unique ticket ID for tracking the review\"\n    },\n    \"queue_status\": {\n      \"type\": \"string\",\n      \"description\": \"Current status: queued, assigned, in_progress, or completed\"\n    }\n  }\n}\n```\n\n```json\n{\n  \"tool_name\": \"Content Flagging System\",\n  \"tool_description\": \"Flags content that violates policies, applies appropriate restrictions, and logs moderation actions for audit trails.\",\n  \"parameters\": {\n    \"content_id\": {\n      \"type\": \"string\",\n      \"required\": true,\n      \"description\": \"Unique identifier for the content being flagged\"\n    },\n    \"flag_type\": {\n      \"type\": \"string\",\n      \"required\": true,\n      \"description\": \"Type of flag: violence, gore, disturbing, or policy_violation\"\n    },\n    \"severity_level\": {\n      \"type\": \"string\",\n      \"required\": true,\n      \"description\": \"Severity of violation: minor, moderate, major, or severe\"\n    },\n    \"action_taken\": {\n      \"type\": \"string\",\n      \"required\": true,\n      \"description\": \"Action applied: warning, restrict, remove, or ban\"\n    },\n    \"violation_details\": {\n      \"type\": \"string\",\n      \"required\": true,\n      \"description\": \"Detailed description of the policy violation\"\n    }\n  },\n  \"error_messages\": [\n    \"Invalid flag type: Use one of [violence, gore, disturbing, policy_violation].\",\n    \"Invalid severity level: Use one of [minor, moderate, major, severe].\",\n    \"Invalid action: Use one of [warning, restrict, remove, ban].\",\n    \"Missing violation details: violation_details cannot be empty.\",\n    \"Flagging system error: Could not process the content flag.\"\n  ],\n  \"usage\": \"Provide content_id, flag_type, severity_level, action_taken, and violation_details to flag content and apply moderation actions.\",\n  \"output_details\": {\n    \"flag_id\": {\n      \"type\": \"string\",\n      \"description\": \"Unique identifier for the created flag\"\n    },\n    \"timestamp\": {\n      \"type\": \"string\",\n      \"description\": \"Timestamp when the flag was created\",\n      \"format\": \"date-time\"\n    },"

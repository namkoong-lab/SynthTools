field_name: speech_and_voice_services
subfield: Speech-to-Text Transcription
task: Transcribe live streaming audio in real-time with low latency
tool_description: "**STEP 1 — Rate task difficulty**\n\nThis task is **hard**. Real-time speech transcription requires handling continuous audio streams, maintaining low latency (typically <300ms), managing buffer synchronization, dealing with network interruptions, and providing accurate transcription across various speakers, accents, and audio quality conditions. The coordination between audio processing, model inference, and output delivery is complex with high impact of errors on user experience.\n\n**STEP 2 — Set a tool budget**\n\nGiven the hard difficulty rating, I'm targeting **17 tools** within the 15–20 range. This accounts for audio stream management, preprocessing, transcription engines, quality control, latency optimization, and output formatting components.\n\n**STEP 3 — List all tool names and dependencies**\n\n1. **Audio Stream Initializer** - Consumes: stream config → Produces: stream handle\n2. **Audio Buffer Manager** - Consumes: raw audio stream → Produces: buffered audio chunks  \n3. **Audio Quality Analyzer** - Consumes: audio chunks → Produces: quality metrics\n4. **Noise Reduction Filter** - Consumes: audio chunks → Produces: filtered audio\n5. **Voice Activity Detector** - Consumes: audio chunks → Produces: speech/silence segments\n6. **Audio Chunk Segmenter** - Consumes: continuous audio → Produces: processing segments\n7. **Real-time Transcriber** - Consumes: audio segments → Produces: text transcriptions\n8. **Confidence Score Calculator** - Consumes: transcription results → Produces: confidence metrics\n9. **Speaker Diarization Engine** - Consumes: audio segments → Produces: speaker labels\n10. **Punctuation Inserter** - Consumes: raw transcriptions → Produces: formatted text\n11. **Word Timestamp Aligner** - Consumes: transcriptions + audio → Produces: time-aligned text\n12. **Latency Monitor** - Consumes: processing timestamps → Produces: latency metrics\n13. **Stream Health Checker** - Consumes: stream status → Produces: health reports\n14. **Output Formatter** - Consumes: transcriptions + metadata → Produces: structured output\n15. **Partial Result Handler** - Consumes: intermediate results → Produces: progressive updates\n16. **Error Recovery Manager** - Consumes: error conditions → Produces: recovery actions\n17. **Performance Metrics Collector** - Consumes: system stats → Produces: performance reports\n\n**STEP 4 — Multi-tool plans**\n\n**Simple Plans:**\n- Basic transcription: Audio Stream Initializer → Audio Buffer Manager → Real-time Transcriber → Output Formatter\n- Quality monitoring: Audio Quality Analyzer → Stream Health Checker → Performance Metrics Collector\n\n**Medium Plans:**\n- Enhanced transcription: Audio Stream Initializer → Audio Buffer Manager → Noise Reduction Filter → Voice Activity Detector → Real-time Transcriber → Confidence Score Calculator → Output Formatter\n- Latency-optimized: Audio Chunk Segmenter → Real-time Transcriber → Partial Result Handler → Latency Monitor → Output Formatter\n\n**Complex Plans:**\n- Full production pipeline: Audio Stream Initializer → Audio Buffer Manager → Audio Quality Analyzer → Noise Reduction Filter → Voice Activity Detector → Audio Chunk Segmenter → Real-time Transcriber → Speaker Diarization Engine → Confidence Score Calculator → Punctuation Inserter → Word Timestamp Aligner → Output Formatter → Latency Monitor\n- Robust streaming: All tools integrated with Error Recovery Manager and Stream Health Checker monitoring throughout\n\n**STEP 5 — Produce tools**\n\n```json\n{\n  \"tool_name\": \"Audio Stream Initializer\",\n  \"tool_description\": \"Initializes and configures a real-time audio stream connection with specified parameters for live transcription processing.\",\n  \"parameters\": {\n    \"stream_url\": {\n      \"type\": \"string\",\n      \"required\": true,\n      \"description\": \"URL or identifier of the audio stream source\"\n    },\n    \"sample_rate\": {\n      \"type\": \"integer\",\n      \"required\": true,\n      \"description\": \"Audio sample rate in Hz (8000, 16000, 44100, 48000)\"\n    },\n    \"channels\"\
  : {\n      \"type\": \"integer\",\n      \"required\": false,\n      \"description\": \"Number of audio channels (1 for mono, 2 for stereo)\",\n      \"default\": 1\n    },\n    \"bit_depth\": {\n      \"type\": \"integer\",\n      \"required\": false,\n      \"description\": \"Audio bit depth (16, 24, 32)\",\n      \"default\": 16\n    }\n  },\n  \"error_messages\": [\n    \"Invalid stream URL: Provide a valid audio stream URL or identifier that is accessible.\",\n    \"Unsupported sample rate: Use one of [8000, 16000, 44100, 48000] Hz.\",\n    \"Invalid channel count: Channels must be 1 (mono) or 2 (stereo).\",\n    \"Unsupported bit depth: Use 16, 24, or 32 bit depth.\",\n    \"Stream connection failed: Unable to establish connection to the audio stream source.\"\n  ],\n  \"usage\": \"Provide stream_url and sample_rate as required parameters. Optionally specify channels and bit_depth. Returns a stream handle and configuration details for downstream processing.\",\n  \"output_details\": {\n    \"stream_handle\": {\n      \"type\": \"string\",\n      \"description\": \"Unique identifier for the initialized audio stream\"\n    },\n    \"actual_sample_rate\": {\n      \"type\": \"integer\",\n      \"description\": \"Confirmed sample rate of the stream\"\n    },\n    \"stream_status\": {\n      \"type\": \"string\",\n      \"description\": \"Current status of the stream connection\"\n    },\n    \"buffer_size\": {\n      \"type\": \"integer\",\n      \"description\": \"Recommended buffer size in samples\"\n    }\n  }\n}\n```\n\n```json\n{\n  \"tool_name\": \"Audio Buffer Manager\",\n  \"tool_description\": \"Manages real-time audio stream buffering, handling incoming audio data and providing consistent chunk delivery for processing.\",\n  \"parameters\": {\n    \"stream_handle\": {\n      \"type\": \"string\",\n      \"required\": true,\n      \"description\": \"Handle from Audio Stream Initializer\"\n    },\n    \"buffer_duration_ms\": {\n      \"type\": \"integer\",\n      \"required\": false,\n      \"description\": \"Buffer duration in milliseconds (100-2000)\",\n      \"default\": 500\n    },\n    \"overlap_ms\": {\n      \"type\": \"integer\",\n      \"required\": false,\n      \"description\": \"Overlap between consecutive buffers in milliseconds (0-200)\",\n      \"default\": 50\n    },\n    \"max_silence_ms\": {\n      \"type\": \"integer\",\n      \"required\": false,\n      \"description\": \"Maximum silence duration before buffer flush (100-5000)\",\n      \"default\": 1000\n    }\n  },\n  \"error_messages\": [\n    \"Invalid stream handle: Provide a valid stream handle from Audio Stream Initializer.\",\n    \"Buffer underrun: Audio stream is not providing data fast enough for real-time processing.\",\n    \"Buffer overflow: Processing is too slow, causing audio data loss.\",\n    \"Invalid buffer duration: Buffer duration must be between 100-2000 milliseconds.\",\n    \"Invalid overlap duration: Overlap must be between 0-200 milliseconds and less than buffer_duration_ms.\"\n  ],\n  \"usage\": \"Provide stream_handle from initialized audio stream. Configure buffer_duration_ms, overlap_ms, and max_silence_ms as needed. Returns buffered audio chunks ready for processing.\",\n  \"output_details\": {\n    \"audio_chunk_id\": {\n      \"type\": \"string\",\n      \"description\": \"Unique identifier for this audio chunk\"\n    },\n    \"chunk_duration_ms\": {\n      \"type\": \"integer\",\n      \"description\": \"Actual duration of the audio chunk\"\n    },\n    \"timestamp\": {\n      \"type\": \"string\",\n      \"description\": \"Timestamp when chunk was captured\"\n    },\n    \"buffer_health\": {\n      \"type\": \"string\",\n      \"description\": \"Current buffer status (healthy, warning, critical)\"\n    },\n    \"samples_count\": {\n      \"type\": \"integer\",\n      \"description\": \"Number of audio samples in this chunk\"\n    }\n  }\n}\n```\n\n```json\n{\n  \"tool_name\": \"Audio Quality Analyzer\",\n  \"tool_description\": \"Analyzes audio quality metrics including signal-to-noise ratio, volume levels,\
  \ and distortion to optimize transcription accuracy.\",\n  \"parameters\": {\n    \"audio_chunk_id\": {\n      \"type\": \"string\",\n      \"required\": true,\n      \"description\": \"Audio chunk identifier from Audio Buffer Manager\"\n    },\n    \"min_snr_db\": {\n      \"type\": \"number\",\n      \"required\": false,\n      \"description\": \"Minimum acceptable SNR in decibels\",\n      \"default\": 10.0\n    },\n    \"min_volume_db\": {\n      \"type\": \"number\",\n      \"required\": false,\n      \"description\": \"Minimum volume threshold in decibels\",\n      \"default\": -40.0\n    }\n  },\n  \"error_messages\": [\n    \"Invalid audio chunk: Provide a valid audio_chunk_id from Audio Buffer Manager.\",\n    \"Audio data corrupted: The audio chunk contains corrupted or invalid data.\",\n    \"Insufficient audio data: Audio chunk is too short for meaningful quality analysis.\"\n  ],\n  \"usage\": \"Provide audio_chunk_id from buffered audio. Optionally set quality thresholds with min_snr_db and min_volume_db. Returns comprehensive quality metrics for the audio segment.\",\n  \"output_details\": {\n    \"snr_db\": {\n      \"type\": \"number\",\n      \"description\": \"Signal-to-noise ratio in decibels\"\n    },\n    \"volume_db\": {\n      \"type\": \"number\",\n      \"description\": \"Average volume level in decibels\"\n    },\n    \"quality_score\": {\n      \"type\": \"number\",\n      \"description\": \"Overall quality score from 0.0 to 1.0\"\n    },\n    \"quality_issues\": {\n      \"type\": \"array\",\n      \"items\": {\n        \"type\": \"string\"\n      },\n      \"description\": \"List of detected quality issues\"\n    },\n    \"recommended_preprocessing\": {\n      \"type\": \"array\",\n      \"items\": {\n        \"type\": \"string\"\n      },\n      \"description\": \"Recommended preprocessing steps\"\n    }\n  }\n}\n```\n\n```json\n{\n  \"tool_name\": \"Noise Reduction Filter\",\n  \"tool_description\": \"Applies noise reduction algorithms to improve audio quality by removing background noise, hum, and other unwanted artifacts.\",\n  \"parameters\": {\n    \"audio_chunk_id\": {\n      \"type\": \"string\",\n      \"required\": true,\n      \"description\": \"Audio chunk identifier to process\"\n    },\n    \"noise_reduction_level\": {\n      \"type\": \"string\",\n      \"required\": false,\n      \"description\": \"Noise reduction intensity: light, moderate, aggressive\",\n      \"default\": \"moderate\"\n    },\n    \"preserve_speech\": {\n      \"type\": \"boolean\",\n      \"required\": false,\n      \"description\": \"Whether to prioritize speech preservation over noise removal\",\n      \"default\": true\n    },\n    \"frequency_cutoff_hz\": {\n      \"type\": \"integer\",\n      \"required\": false,\n      \"description\": \"High-pass filter cutoff frequency (50-500 Hz)\",\n      \"default\": 80\n    }\n  },\n  \"error_messages\": [\n    \"Invalid audio chunk: Provide a valid audio_chunk_id.\",\n    \"Invalid noise reduction level: Use 'light', 'moderate', or 'aggressive'.\",\n    \"Invalid frequency cutoff: Cutoff frequency must be between 50-500 Hz.\",\n    \"Processing failed: Audio filtering encountered an error, possibly due to corrupted audio data.\"\n  ],\n  \"usage\": \"Provide audio_chunk_id for processing. Configure noise_reduction_level, preserve_speech, and frequency_cutoff_hz as needed. Returns filtered audio with reduced background noise.\",\n  \"output_details\": {\n    \"filtered_chunk_id\": {\n      \"type\": \"string\",\n      \"description\": \"Identifier for the noise-filtered audio chunk\"\n    },\n    \"noise_reduction_applied\": {\n      \"type\": \"number\",\n      \"description\": \"Amount of noise reduction applied (0.0 to 1.0)\"\n    },\n    \"processing_time_ms\": {\n      \"type\": \"integer\",\n      \"description\": \"Time taken to process the audio chunk\"\n    },\n    \"quality_improvement\": {\n      \"type\": \"number\",\n      \"description\": \"Estimated quality improvement score\"\n    }\n  }\n}\n```\n\n```json\n{\n  \"tool_name\": \"Voice Activity\
  \ Detector\",\n  \"tool_description\": \"Detects speech segments in audio streams, distinguishing between speech and silence to optimize transcription processing and reduce computational overhead.\",\n  \"parameters\": {\n    \"audio_chunk_id\": {\n      \"type\": \"string\",\n      \"required\": true,\n      \"description\": \"Audio chunk identifier to analyze\"\n    },\n    \"sensitivity\": {\n      \"type\": \"number\",\n      \"required\": false,\n      \"description\": \"Detection sensitivity from 0.1 to 1.0\",\n      \"default\": 0.5\n    },\n    \"min_speech_duration_ms\": {\n      \"type\": \"integer\",\n      \"required\": false,\n      \"description\": \"Minimum speech segment duration (50-500 ms)\",\n      \"default\": 100\n    },\n    \"min_silence_duration_ms\": {\n      \"type\": \"integer\",\n      \"required\": false,\n      \"description\": \"Minimum silence duration to split segments (100-2000 ms)\",\n      \"default\": 300\n    }\n  },\n  \"error_messages\": [\n    \"Invalid audio chunk: Provide a valid audio_chunk_id.\",\n    \"Invalid sensitivity: Sensitivity must be between 0.1 and 1.0.\",\n    \"Invalid speech duration: min_speech_duration_ms must be between 50-500 milliseconds.\",\n    \"Invalid silence duration: min_silence_duration_ms must be between 100-2000 milliseconds.\"\n  ],\n  \"usage\": \"Provide audio_chunk_id for analysis. Configure sensitivity and minimum durations as needed. Returns speech activity detection results with segment boundaries.\",\n  \"output_details\": {\n    \"has_speech\": {\n      \"type\": \"boolean\",\n      \"description\": \"Whether speech was detected in the chunk\"\n    },\n    \"speech_probability\": {\n      \"type\": \"number\",\n      \"description\": \"Probability of speech presence (0.0 to 1.0)\"\n    },\n    \"speech_segments\": {\n      \"type\": \"array\",\n      \"items\": {\n        \"type\": \"string\"\n      },\n      \"description\": \"List of detected speech segment identifiers\"\n    },\n    \"total_speech_duration_ms\": {\n      \"type\": \"integer\",\n      \"description\": \"Total duration of speech in the chunk\"\n    },\n    \"confidence\": {\n      \"type\": \"number\",\n      \"description\": \"Confidence score of the detection\"\n    }\n  }\n}\n```\n\n```json\n{\n  \"tool_name\": \"Audio Chunk Segmenter\",\n  \"tool_description\": \"Segments continuous audio into optimal chunks for transcription processing, considering speech boundaries and computational efficiency.\",\n  \"parameters\": {\n    \"audio_chunk_id\": {\n      \"type\": \"string\",\n      \"required\": true,\n      \"description\": \"Input audio chunk to segment\"\n    },\n    \"target_segment_ms\": {\n      \"type\": \"integer\",\n      \"required\": false,\n      \"description\": \"Target segment duration in milliseconds (200-5000)\",\n      \"default\": 1000\n    },\n    \"respect_speech_boundaries\": {\n      \"type\": \"boolean\",\n      \"required\": false,\n      \"description\": \"Whether to avoid cutting speech in the middle\",\n      \"default\": true\n    },\n    \"max_segment_ms\": {\n      \"type\": \"integer\",\n      \"required\": false,\n      \"description\": \"Maximum allowed segment duration (1000-10000 ms)\",\n      \"default\": 3000\n    },\n    \"min_segment_ms\": {\n      \"type\": \"integer\",\n      \"required\": false,\n      \"description\": \"Minimum segment duration (100-1000 ms)\",\n      \"default\": 200\n    }\n  },\n  \"error_messages\": [\n    \"Invalid audio chunk: Provide a valid audio_chunk_id.\",\n    \"Invalid target segment duration: target_segment_ms must be between 200-5000 milliseconds.\",\n    \"Invalid maximum segment duration: max_segment_ms must be between 1000-10000 milliseconds and greater than target_segment_ms.\",\n    \"Invalid minimum segment duration: min_segment_ms must be between 100-1000 milliseconds and less than target_segment_ms.\",\n    \"Segmentation failed: Unable to segment audio chunk according to specified parameters.\"\n  ],\n  \"usage\": \"Provide audio_chunk_id for segmentation. Configure timing parameters\
  \ and boundary respect settings. Returns optimally segmented audio chunks ready for transcription.\",\n  \"output_details\": {\n    \"segment_ids\": {\n      \"type\": \"array\",\n      \"items\": {\n        \"type\": \"string\"\n      },\n      \"description\": \"List of generated segment identifiers\"\n    },\n    \"segment_count\": {\n      \"type\": \"integer\",\n      \"description\": \"Number of segments created\"\n    },\n    \"avg_segment_duration_ms\": {\n      \"type\": \"integer\",\n      \"description\": \"Average duration of created segments\"\n    },\n    \"boundaries_respected\": {\n      \"type\": \"boolean\",\n      \"description\": \"Whether speech boundaries were successfully preserved\"\n    }\n  }\n}\n```\n\n```json\n{\n  \"tool_name\": \"Real-time Transcriber\",\n  \"tool_description\": \"Performs speech-to-text transcription on audio segments using specified models and configurations optimized for low-latency real-time processing.\",\n  \"parameters\": {\n    \"audio_segment_id\": {\n      \"type\": \"string\",\n      \"required\": true,\n      \"description\": \"Audio segment identifier to transcribe\"\n    },\n    \"model_name\": {\n      \"type\": \"string\",\n      \"required\": true,\n      \"description\": \"Transcription model: whisper-tiny, whisper-base, whisper-small, wav2vec2, deepspeech\"\n    },\n    \"language\": {\n      \"type\": \"string\",\n      \"required\": false,\n      \"description\": \"Target language code (en, es, fr, de, etc.)\",\n      \"default\": \"en\"\n    },\n    \"beam_size\": {\n      \"type\": \"integer\",\n      \"required\": false,\n      \"description\": \"Beam search width (1-10)\",\n      \"default\": 3\n    },\n    \"temperature\": {\n      \"type\": \"number\",\n      \"required\": false,\n      \"description\": \"Sampling temperature (0.0-1.0)\",\n      \"default\": 0.2\n    },\n    \"max_tokens\": {\n      \"type\": \"integer\",\n      \"required\": false,\n      \"description\": \"Maximum tokens to generate (10-500)\",\n      \"default\": 100\n    },\n    \"enable_vad\": {\n      \"type\": \"boolean\",\n      \"required\": false,\n      \"description\": \"Enable voice activity detection preprocessing\",\n      \"default\": true\n    },\n    \"output_format\": {\n      \"type\": \"string\",\n      \"required\": false,\n      \"description\": \"Output format: text, json, srt\",\n      \"default\": \"text\"\n    }\n  },\n  \"error_messages\": [\n    \"Invalid audio segment: Provide a valid audio_segment_id.\",\n    \"Unsupported model: Use one of [whisper-tiny, whisper-base, whisper-small, wav2vec2, deepspeech].\",\n    \"Unsupported language: Provide a valid language code supported by the selected model.\",\n    \"Invalid beam size: beam_size must be between 1-10.\",\n    \"Invalid temperature: temperature must be between 0.0-1.0.\",\n    \"Invalid max tokens: max_tokens must be between 10-500.\",\n    \"Model loading failed: Unable to load the specified transcription model.\",\n    \"Transcription timeout: Processing took too long, consider using a faster model or shorter segments.\"\n  ],\n  \"usage\": \"Provide audio_segment_id and model_name. Configure language, beam_size, temperature, and other parameters as needed. Returns transcribed text with metadata and timing information.\",\n  \"output_details\": {\n    \"transcription\": {\n      \"type\": \"string\",\n      \"description\": \"The transcribed text from the audio segment\"\n    },\n    \"processing_time_ms\": {\n      \"type\": \"integer\",\n      \"description\": \"Time taken for transcription processing\"\n    },\n    \"model_used\": {\n      \"type\": \"string\",\n      \"description\": \"Name of the model used for transcription\"\n    },\n    \"language_detected\": {\n      \"type\": \"string\",\n      \"description\": \"Detected language of the audio\"\n    },\n    \"segment_duration_ms\": {\n      \"type\": \"integer\",\n      \"description\": \"Duration of the processed audio segment\"\n    }\n  }\n}\n```\n\n```json\n{\n  \"tool_name\": \"Confidence Score Calculator\",\n  \"tool_description\"\
  : \"Calculates confidence scores for transcription results based on model outputs, audio quality, and linguistic consistency to assess transcription reliability.\",\n  \"parameters\": {\n    \"transcription_text\": {\n      \"type\": \"string\",\n      \"required\": true,\n      \"description\": \"Transcribed text to analyze\"\n    },\n    \"model_name\": {\n      \"type\": \"string\",\n      \"required\": true,\n      \"description\": \"Name of the model used for transcription\"\n    },\n    \"audio_quality_score\": {\n      \"type\": \"number\",\n      \"required\": false,\n      \"description\": \"Audio quality score from 0.0 to 1.0\",\n      \"default\": 0.8\n    },\n    \"processing_time_ms\": {\n      \"type\": \"integer\",\n      \"required\": false,\n      \"description\": \"Time taken for transcription\",\n      \"default\": 100\n    }\n  },\n  \"error_messages\": [\n    \"Empty transcription: Provide a non-empty transcription_text for analysis.\",\n    \"Invalid model name: Provide the name of the model used for generating the transcription.\",\n    \"Invalid audio quality score: audio_quality_score must be between 0.0 and 1.0.\",\n    \"Invalid processing time: processing_time_ms must be a positive integer.\"\n  ],\n  \"usage\": \"Provide transcription_text and model_name as required parameters. Optionally include audio_quality_score and processing_time_ms. Returns comprehensive confidence metrics for the transcription.\",\n  \"output_details\": {\n    \"overall_confidence\": {\n      \"type\": \"number\",\n      \"description\": \"Overall confidence score from 0.0 to 1.0\"\n    },\n    \"word_confidence_avg\": {\n      \"type\": \"number\",\n      \"description\": \"Average per-word confidence score\"\n    },\n    \"linguistic_consistency\": {\n      \"type\": \"number\",\n      \"description\": \"Score for linguistic consistency and grammar\"\n    },\n    \"low_confidence_words\": {\n      \"type\": \"array\",\n      \"items\": {\n        \"type\": \"string\"\n      },\n      \"description\": \"List of words with low confidence scores\"\n    },\n    \"reliability_rating\": {\n      \"type\": \"string\",\n      \"description\": \"Reliability assessment: high, medium, low\"\n    }\n  }\n}\n```\n\n```json\n{\n  \"tool_name\": \"Speaker Diarization Engine\",\n  \"tool_description\": \"Identifies and labels different speakers in audio segments, providing speaker separation and tracking for multi-speaker transcription scenarios.\",\n  \"parameters\": {\n    \"audio_segment_id\": {\n      \"type\": \"string\",\n      \"required\": true,\n      \"description\": \"Audio segment identifier for speaker analysis\"\n    },\n    \"min_speakers\": {\n      \"type\": \"integer\",\n      \"required\": false,\n      \"description\": \"Minimum number of speakers to detect (1-10)\",\n      \"default\": 1\n    },\n    \"max_speakers\": {\n      \"type\": \"integer\",\n      \"required\": false,\n      \"description\": \"Maximum number of speakers to detect (1-10)\",\n      \"default\": 5\n    },\n    \"speaker_change_threshold\": {\n      \"type\": \"number\",\n      \"required\": false,\n      \"description\": \"Sensitivity for speaker change detection (0.1-1.0)\",\n      \"default\": 0.5\n    }\n  },\n  \"error_messages\": [\n    \"Invalid audio segment: Provide a valid audio_segment_id.\",\n    \"Invalid speaker count: min_speakers and max_speakers must be between 1-10, with min_speakers <= max_speakers.\",\n    \"Invalid threshold: speaker_change_threshold must be between 0.1-1.0.\",\n    \"Diarization failed: Unable to perform speaker diarization on the provided audio segment.\",\n    \"Insufficient audio: Audio segment too short for reliable speaker diarization.\"\n  ],\n  \"usage\": \"Provide audio_segment_id for speaker analysis. Configure speaker count limits and change detection sensitivity. Returns speaker labels and timing information.\",\n  \"output_details\": {\n    \"speaker_count\": {\n      \"type\": \"integer\",\n      \"description\": \"Number of unique speakers detected\"\n    },\n    \"speaker_segments\": {\n\
  \      \"type\": \"array\",\n      \"items\": {\n        \"type\": \"string\"\n      },\n      \"description\": \"List of speaker segment identifiers with labels\"\n    },\n    \"dominant_speaker\": {\n      \"type\": \"string\",\n      \"description\": \"Label of the speaker with most speaking time\"\n    },\n    \"speaker_changes\": {\n      \"type\": \"integer\",\n      \"description\": \"Number of speaker changes detected\"\n    },\n    \"confidence\": {\n      \"type\": \"number\",\n      \"description\": \"Confidence in speaker diarization results\"\n    }\n  }\n}\n```\n\n```json\n{\n  \"tool_name\": \"Punctuation Inserter\",\n  \"tool_description\": \"Adds appropriate punctuation and capitalization to raw transcription text to improve readability and grammatical correctness.\",\n  \"parameters\": {\n    \"raw_text\": {\n      \"type\": \"string\",\n      \"required\": true,\n      \"description\": \"Raw transcription text without punctuation\"\n    },\n    \"language\": {\n      \"type\": \"string\",\n      \"required\": false,\n      \"description\": \"Language code for punctuation rules (en, es, fr, de)\",\n      \"default\": \"en\"\n    },\n    \"capitalization_style\": {\n      \"type\": \"string\",\n      \"required\": false,\n      \"description\": \"Capitalization style: sentence, title, none\",\n      \"default\": \"sentence\"\n    }\n  },\n  \"error_messages\": [\n    \"Empty text: Provide non-empty raw_text for punctuation processing.\",\n    \"Unsupported language: Use one of [en, es, fr, de] for language code.\",\n    \"Invalid capitalization style: Use 'sentence', 'title', or 'none'.\",\n    \"Processing failed: Unable to process the text for punctuation insertion.\"\n  ],\n  \"usage\": \"Provide raw_text from transcription. Optionally specify language and capitalization_style. Returns properly punctuated and formatted text.\",\n  \"output_details\": {\n    \"formatted_text\": {\n      \"type\": \"string\",\n      \"description\": \"Text with punctuation and capitalization applied\"\n    },\n    \"punctuation_added\": {\n      \"type\": \"integer\",\n      \"description\": \"Number of punctuation marks added\"\n    },\n    \"words_capitalized\": {\n      \"type\": \"integer\",\n      \"description\": \"Number of words that were capitalized\"\n    },\n    \"processing_confidence\": {\n      \"type\": \"number\",\n      \"description\": \"Confidence in punctuation accuracy\"\n    }\n  }\n}\n```\n\n```json\n{\n  \"tool_name\": \"Word Timestamp Aligner\",\n  \"tool_description\": \"Aligns transcribed words with precise timestamps from the original audio, providing word-level timing information for synchronized playback and navigation.\",\n  \"parameters\": {\n    \"transcription_text\": {\n      \"type\": \"string\",\n      \"required\": true,\n      \"description\": \"Transcribed text to align with timestamps\"\n    },\n    \"audio_segment_id\": {\n      \"type\": \"string\",\n      \"required\": true,\n      \"description\": \"Audio segment identifier used for transcription\"\n    },\n    \"segment_start_time\": {\n      \"type\": \"string\",\n      \"required\": true,\n      \"description\": \"Start timestamp of the audio segment\",\n      \"format\": \"date-time\"\n    },\n    \"alignment_precision\": {\n      \"type\": \"string\",\n      \"required\": false,\n      \"description\": \"Alignment precision: word, phrase, sentence\",\n      \"default\": \"word\"\n    },\n    \"force_alignment\": {\n      \"type\": \"boolean\",\n      \"required\": false,\n      \"description\": \"Force alignment even with low confidence\",\n      \"default\": false\n    }\n  },\n  \"error_messages\": [\n    \"Empty transcription: Provide non-empty transcription_text for alignment.\",\n    \"Invalid audio segment: Provide a valid audio_segment_id.\",\n    \"Invalid timestamp: segment_start_time must be a valid ISO 8601 datetime string.\",\n    \"Invalid precision: alignment_precision must be 'word', 'phrase', or 'sentence'.\",\n    \"Alignment failed: Unable to align text with audio timestamps.\",\n    \"Duration mismatch:\
  \ Transcription length doesn't match audio segment duration.\"\n  ],\n  \"usage\": \"Provide transcription_text, audio_segment_id, and segment_start_time. Configure alignment_precision and force_alignment as needed. Returns word-level timestamps for synchronized text display.\",\n  \"output_details\": {\n    \"aligned_words\": {\n      \"type\": \"array\",\n      \"items\": {\n        \"type\": \"string\"\n      },\n      \"description\": \"List of words with their aligned timestamps\"\n    },\n    \"total_words\": {\n      \"type\": \"integer\",\n      \"description\": \"Total number of words aligned\"\n    },\n    \"alignment_confidence\": {\n      \"type\": \"number\",\n      \"description\": \"Overall alignment confidence score\"\n    },\n    \"average_word_duration_ms\": {\n      \"type\": \"integer\",\n      \"description\": \"Average duration per word in milliseconds\"\n    },\n    \"alignment_quality\": {\n      \"type\": \"string\",\n      \"description\": \"Quality assessment of the alignment\"\n    }\n  }\n}\n```\n\n```json\n{\n  \"tool_name\": \"Latency Monitor\",\n  \"tool_description\": \"Monitors and tracks latency metrics throughout the real-time transcription pipeline to ensure low-latency performance requirements are met.\",\n  \"parameters\": {\n    \"process_start_time\": {\n      \"type\": \"string\",\n      \"required\": true,\n      \"description\": \"Start timestamp of the process being monitored\",\n      \"format\": \"date-time\"\n    },\n    \"process_end_time\": {\n      \"type\": \"string\",\n      \"required\": true,\n      \"description\": \"End timestamp of the process being monitored\",\n      \"format\": \"date-time\"\n    },\n    \"target_latency_ms\": {\n      \"type\": \"integer\",\n      \"required\": false,\n      \"description\": \"Target maximum latency in milliseconds\",\n      \"default\": 300\n    }\n  },\n  \"error_messages\": [\n    \"Invalid timestamps: Provide valid ISO 8601 datetime strings for process_start_time and process_end_time.\",\n    \"Timeline error: process_end_time must be after process_start_time.\",\n    \"Invalid target latency: target_latency_ms must be a positive integer.\",\n    \"Calculation failed: Unable to calculate latency metrics from provided timestamps.\"\n  ],\n  \"usage\": \"Provide process_start_time and process_end_time for latency calculation. Set target_latency_ms for performance evaluation. Returns detailed latency metrics and performance assessment.\",\n  \"output_details\": {\n    \"actual_latency_ms\": {\n      \"type\": \"integer\",\n      \"description\": \"Actual latency measured in milliseconds\"\n    },\n    \"target_met\": {\n      \"type\":"

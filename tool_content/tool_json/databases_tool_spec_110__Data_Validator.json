{
  "tool_name": "Data Validator",
  "tool_description": "Validates extracted data for completeness, consistency, and quality issues before transformation.",
  "parameters": {
    "data_source": {
      "type": "string",
      "required": true,
      "description": "Path or identifier for the data to validate"
    },
    "schema_definition": {
      "type": "string",
      "required": true,
      "description": "JSON string defining expected data schema"
    },
    "validation_rules": {
      "type": "array",
      "items": {
        "type": "string"
      },
      "required": false,
      "default": [],
      "description": "Custom validation rules to apply"
    },
    "sample_size": {
      "type": "integer",
      "required": false,
      "default": 10000,
      "description": "Number of records to sample for validation"
    },
    "null_tolerance": {
      "type": "number",
      "required": false,
      "default": 0.05,
      "description": "Maximum acceptable percentage of null values (0-1)"
    },
    "duplicate_check": {
      "type": "boolean",
      "required": false,
      "default": true,
      "description": "Whether to check for duplicate records"
    },
    "data_profiling": {
      "type": "boolean",
      "required": false,
      "default": false,
      "description": "Whether to perform detailed data profiling"
    }
  },
  "error_messages": [
    "Data source not found: Unable to access specified data source for validation.",
    "Invalid schema definition: Schema JSON is malformed or missing required fields.",
    "Invalid validation rules: Custom validation rules contain syntax errors.",
    "Sample size out of range: Sample size must be between 100 and 1000000.",
    "Invalid null tolerance: Null tolerance must be between 0 and 1.",
    "Validation failed: Data does not meet quality thresholds for migration."
  ],
  "usage": "Provide data_source and schema_definition to validate data quality. Configure validation parameters and rules based on data quality requirements. Review validation results before proceeding with transformation.",
  "output_details": {
    "validation_passed": {
      "type": "boolean",
      "description": "Whether data passed all validation checks"
    },
    "quality_score": {
      "type": "number",
      "description": "Overall data quality score (0-1)"
    },
    "null_percentage": {
      "type": "number",
      "description": "Percentage of null values found"
    },
    "duplicate_count": {
      "type": "integer",
      "description": "Number of duplicate records identified"
    },
    "validation_errors": {
      "type": "array",
      "items": {
        "type": "string"
      },
      "description": "List of validation errors found"
    },
    "data_profile": {
      "type": "string",
      "description": "Detailed data profiling results if requested"
    }
  }
}
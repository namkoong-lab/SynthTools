{
  "tool_name": "Topic Modeler",
  "tool_description": "Applies topic modeling algorithms like LDA to discover latent topics in review collections, identifying topic distributions and representative terms for each discovered topic.",
  "parameters": {
    "texts": {
      "type": "array",
      "required": true,
      "description": "Array of preprocessed review texts for topic modeling",
      "items": {
        "type": "string"
      },
      "minItems": 20,
      "maxItems": 50000
    },
    "num_topics": {
      "type": "integer",
      "required": false,
      "default": 8,
      "description": "Number of topics to discover (2-50)"
    },
    "algorithm": {
      "type": "string",
      "required": false,
      "default": "lda",
      "description": "Topic modeling algorithm: lda, nmf, or bertopic"
    },
    "max_iterations": {
      "type": "integer",
      "required": false,
      "default": 100,
      "description": "Maximum iterations for model training"
    },
    "alpha": {
      "type": "number",
      "required": false,
      "default": 0.1,
      "description": "Document-topic density parameter (0.01-2.0)"
    },
    "beta": {
      "type": "number",
      "required": false,
      "default": 0.01,
      "description": "Topic-word density parameter (0.001-0.1)"
    },
    "random_seed": {
      "type": "integer",
      "required": false,
      "default": 42,
      "description": "Random seed for reproducible results"
    },
    "min_word_freq": {
      "type": "integer",
      "required": false,
      "default": 5,
      "description": "Minimum word frequency for inclusion in model"
    },
    "max_vocab_size": {
      "type": "integer",
      "required": false,
      "default": 5000,
      "description": "Maximum vocabulary size for model"
    },
    "remove_stopwords": {
      "type": "boolean",
      "required": false,
      "default": true,
      "description": "Whether to remove stopwords from texts"
    },
    "coherence_metric": {
      "type": "string",
      "required": false,
      "default": "c_v",
      "description": "Topic coherence metric: c_v, u_mass, or c_npmi"
    }
  },
  "error_messages": [
    "Insufficient documents: Provide at least 20 texts for reliable topic modeling.",
    "Invalid topic count: num_topics must be between 2 and 50.",
    "Unsupported algorithm: Use lda, nmf, or bertopic for the algorithm parameter.",
    "Parameter out of range: alpha must be between 0.01-2.0, beta between 0.001-0.1.",
    "Invalid iteration count: max_iterations must be between 10 and 1000.",
    "Vocabulary too small: Texts contain insufficient unique words for modeling.",
    "Model convergence failed: Topic model failed to converge with current parameters.",
    "Unsupported coherence metric: Use c_v, u_mass, or c_npmi for coherence_metric."
  ],
  "usage": "Provide a collection of review texts and configure topic modeling parameters. The tool discovers latent topics and returns topic distributions and representative terms.",
  "output_details": {
    "topic_labels": {
      "type": "array",
      "items": {
        "type": "string"
      },
      "description": "Array of descriptive labels for discovered topics"
    },
    "topic_terms": {
      "type": "array",
      "items": {
        "type": "string"
      },
      "description": "Array of top terms for each topic (comma-separated)"
    },
    "document_topics": {
      "type": "array",
      "items": {
        "type": "string"
      },
      "description": "Array of dominant topic assignments for each document"
    },
    "topic_weights": {
      "type": "array",
      "items": {
        "type": "number"
      },
      "description": "Array of topic prevalence weights in the corpus"
    },
    "coherence_score": {
      "type": "number",
      "description": "Overall topic coherence score"
    },
    "perplexity": {
      "type": "number",
      "description": "Model perplexity score (lower is better)"
    },
    "modeling_summary": {
      "type": "string",
      "description": "Summary of topic modeling results and quality metrics"
    }
  }
}
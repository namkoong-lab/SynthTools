{
  "tool_name": "Real-time Transcriber",
  "tool_description": "Performs speech-to-text transcription on audio segments using specified models and configurations optimized for low-latency real-time processing.",
  "parameters": {
    "audio_segment_id": {
      "type": "string",
      "required": true,
      "description": "Audio segment identifier to transcribe"
    },
    "model_name": {
      "type": "string",
      "required": true,
      "description": "Transcription model: whisper-tiny, whisper-base, whisper-small, wav2vec2, deepspeech"
    },
    "language": {
      "type": "string",
      "required": false,
      "description": "Target language code (en, es, fr, de, etc.)",
      "default": "en"
    },
    "beam_size": {
      "type": "integer",
      "required": false,
      "description": "Beam search width (1-10)",
      "default": 3
    },
    "temperature": {
      "type": "number",
      "required": false,
      "description": "Sampling temperature (0.0-1.0)",
      "default": 0.2
    },
    "max_tokens": {
      "type": "integer",
      "required": false,
      "description": "Maximum tokens to generate (10-500)",
      "default": 100
    },
    "enable_vad": {
      "type": "boolean",
      "required": false,
      "description": "Enable voice activity detection preprocessing",
      "default": true
    },
    "output_format": {
      "type": "string",
      "required": false,
      "description": "Output format: text, json, srt",
      "default": "text"
    }
  },
  "error_messages": [
    "Invalid audio segment: Provide a valid audio_segment_id.",
    "Unsupported model: Use one of [whisper-tiny, whisper-base, whisper-small, wav2vec2, deepspeech].",
    "Unsupported language: Provide a valid language code supported by the selected model.",
    "Invalid beam size: beam_size must be between 1-10.",
    "Invalid temperature: temperature must be between 0.0-1.0.",
    "Invalid max tokens: max_tokens must be between 10-500.",
    "Model loading failed: Unable to load the specified transcription model.",
    "Transcription timeout: Processing took too long, consider using a faster model or shorter segments."
  ],
  "usage": "Provide audio_segment_id and model_name. Configure language, beam_size, temperature, and other parameters as needed. Returns transcribed text with metadata and timing information.",
  "output_details": {
    "transcription": {
      "type": "string",
      "description": "The transcribed text from the audio segment"
    },
    "processing_time_ms": {
      "type": "integer",
      "description": "Time taken for transcription processing"
    },
    "model_used": {
      "type": "string",
      "description": "Name of the model used for transcription"
    },
    "language_detected": {
      "type": "string",
      "description": "Detected language of the audio"
    },
    "segment_duration_ms": {
      "type": "integer",
      "description": "Duration of the processed audio segment"
    }
  }
}
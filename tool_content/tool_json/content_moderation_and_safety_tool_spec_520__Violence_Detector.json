{
  "tool_name": "Violence Detector",
  "tool_description": "Identifies violent imagery including weapons, blood, fighting, and aggressive behavior using computer vision models specialized in violence detection.",
  "parameters": {
    "image_path": {
      "type": "string",
      "required": true,
      "description": "Path to the preprocessed image file"
    },
    "violence_types": {
      "type": "array",
      "items": {
        "type": "string"
      },
      "required": false,
      "description": "Types of violence to detect: 'blood', 'fighting', 'weapons', 'injury'",
      "default": [
        "blood",
        "fighting",
        "weapons",
        "injury"
      ]
    },
    "sensitivity": {
      "type": "string",
      "required": false,
      "description": "Detection sensitivity: 'conservative', 'balanced', or 'aggressive'",
      "default": "balanced"
    }
  },
  "error_messages": [
    "Image file error: Cannot access or read the specified image file.",
    "Invalid violence types: Use valid types from ['blood', 'fighting', 'weapons', 'injury'].",
    "Invalid sensitivity setting: Use 'conservative', 'balanced', or 'aggressive' for sensitivity parameter.",
    "Analysis failure: Violence detection algorithm failed to process image."
  ],
  "usage": "Provide image_path to detect violent content. Specify violence_types array to focus on particular violence categories. Adjust sensitivity based on platform policy requirements.",
  "output_details": {
    "violence_detected": {
      "type": "boolean",
      "description": "Whether any violence indicators were found"
    },
    "violence_score": {
      "type": "number",
      "description": "Overall violence likelihood score (0.0-1.0)"
    },
    "detected_types": {
      "type": "array",
      "items": {
        "type": "string"
      },
      "description": "Specific types of violence detected"
    },
    "severity_level": {
      "type": "string",
      "description": "Violence severity: 'mild', 'moderate', 'severe', or 'extreme'"
    }
  }
}
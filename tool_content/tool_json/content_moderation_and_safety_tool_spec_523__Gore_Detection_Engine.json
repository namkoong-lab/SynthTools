{
  "tool_name": "Gore Detection Engine",
  "tool_description": "Identifies gore, blood, graphic injuries, and disturbing imagery in visual content using specialized computer vision models.",
  "parameters": {
    "image_paths": {
      "type": "array",
      "required": true,
      "description": "Paths to image files to analyze for gore content",
      "items": {
        "type": "string"
      },
      "minItems": 1,
      "maxItems": 100
    },
    "gore_categories": {
      "type": "array",
      "required": false,
      "description": "Specific gore categories to detect",
      "items": {
        "type": "string"
      },
      "default": [
        "blood",
        "injuries",
        "corpses",
        "dismemberment",
        "medical_gore"
      ]
    },
    "sensitivity_level": {
      "type": "string",
      "required": false,
      "description": "Detection sensitivity: conservative, balanced, or aggressive",
      "default": "balanced"
    },
    "medical_context_filter": {
      "type": "boolean",
      "required": false,
      "description": "Apply filtering for legitimate medical/educational content",
      "default": true
    }
  },
  "error_messages": [
    "Image processing failed: One or more images could not be processed for gore detection.",
    "Invalid sensitivity level: Use one of [conservative, balanced, aggressive].",
    "Invalid gore categories: Specify valid categories from the supported list.",
    "Batch size exceeded: Maximum 100 images per request.",
    "Gore detection model unavailable: The detection model is currently unavailable."
  ],
  "usage": "Provide image_paths array for gore analysis. Optionally configure gore_categories, sensitivity_level, and medical_context_filter.",
  "output_details": {
    "overall_gore_score": {
      "type": "number",
      "description": "Overall gore severity score (0.0-1.0)"
    },
    "image_gore_scores": {
      "type": "array",
      "items": {
        "type": "number"
      },
      "description": "Gore score for each analyzed image"
    },
    "detected_gore_types": {
      "type": "array",
      "items": {
        "type": "string"
      },
      "description": "Types of gore content detected"
    },
    "flagged_images": {
      "type": "array",
      "items": {
        "type": "string"
      },
      "description": "Paths to images flagged for gore content"
    },
    "medical_context_detected": {
      "type": "boolean",
      "description": "Whether medical/educational context was detected"
    }
  }
}
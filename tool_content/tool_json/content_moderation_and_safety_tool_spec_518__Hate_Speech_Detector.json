{
  "tool_name": "Hate Speech Detector",
  "tool_description": "Detects hate speech targeting individuals or groups based on protected characteristics using specialized classification models.",
  "parameters": {
    "text_content": {
      "type": "string",
      "required": true,
      "description": "Text content to analyze for hate speech"
    },
    "target_groups": {
      "type": "array",
      "items": {
        "type": "string"
      },
      "required": false,
      "description": "Specific target groups to focus detection on",
      "default": []
    },
    "sensitivity_level": {
      "type": "string",
      "required": false,
      "description": "Detection sensitivity: low, medium, high",
      "default": "medium"
    },
    "include_context_analysis": {
      "type": "boolean",
      "required": false,
      "description": "Whether to include contextual analysis for borderline cases",
      "default": true
    }
  },
  "error_messages": [
    "Empty text content: Provide non-empty text for hate speech detection.",
    "Invalid sensitivity level: Use low, medium, or high.",
    "Unsupported target group: One or more specified target groups are not supported.",
    "Analysis timeout: Content too complex for processing within time limits."
  ],
  "usage": "Provide text_content for analysis. Optionally specify target_groups for focused detection. Set sensitivity_level based on moderation requirements.",
  "output_details": {
    "is_hate_speech": {
      "type": "boolean",
      "description": "Whether content contains hate speech"
    },
    "hate_score": {
      "type": "number",
      "description": "Hate speech confidence score (0.0-1.0)"
    },
    "targeted_groups": {
      "type": "array",
      "items": {
        "type": "string"
      },
      "description": "List of groups that appear to be targeted"
    },
    "hate_categories": {
      "type": "array",
      "items": {
        "type": "string"
      },
      "description": "Types of hate speech detected"
    }
  }
}
{
  "tool_name": "Violence Detector",
  "tool_description": "Identifies violent content, weapons, blood, and aggressive behavior in images.",
  "parameters": {
    "image_path": {
      "type": "string",
      "required": true,
      "description": "Path to the image file to analyze"
    },
    "detection_types": {
      "type": "array",
      "items": {
        "type": "string"
      },
      "required": false,
      "description": "Types of violence to detect: weapons, blood, fighting, gore",
      "default": [
        "weapons",
        "blood",
        "fighting"
      ]
    },
    "sensitivity": {
      "type": "string",
      "required": false,
      "description": "Detection sensitivity: strict, moderate, lenient",
      "default": "moderate"
    }
  },
  "error_messages": [
    "Image not found: The specified image file does not exist or is not readable.",
    "Invalid detection types: detection_types must contain only: weapons, blood, fighting, gore.",
    "Invalid sensitivity: sensitivity must be one of: strict, moderate, lenient.",
    "Detection failed: Unable to analyze image for violence. Check file format and integrity."
  ],
  "usage": "Provide image_path and optionally specify which types of violence to detect and sensitivity level. Stricter sensitivity catches more potential issues but may have more false positives.",
  "output_details": {
    "violence_detected": {
      "type": "boolean",
      "description": "Whether violent content was detected"
    },
    "violence_score": {
      "type": "number",
      "description": "Overall violence confidence score (0.0-1.0)"
    },
    "detected_types": {
      "type": "array",
      "items": {
        "type": "string"
      },
      "description": "Specific types of violence detected"
    },
    "severity_level": {
      "type": "string",
      "description": "Violence severity: mild, moderate, severe, extreme"
    }
  }
}